{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SSDの損失関数クラスMultiBoxLossの実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 目標\n",
    "1.\tjaccard係数を用いたmatch関数の動作を理解する\n",
    "2.\tHard Negative Miningを理解する\n",
    "3.\t2種類の損失関数（SmoothL1Loss関数、交差エントロピー誤差関数）の働きを理解する\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 8732個のDBoxから正解DBoxと近いDBoxを抽出する関数\n",
    "from utils.match import match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiBoxLoss(nn.Module):\n",
    "    def __init__(self, jaccard_thresh=0.5, neg_pos=3, device='cpu'):\n",
    "        # 親クラスのコンストラクタを実行\n",
    "        super(self).__init__()\n",
    "        \n",
    "        self.jaccard_thresh = jaccard_thresh\n",
    "        self.negpos_ratio = neg_pos\n",
    "        self.device = device\n",
    "        \n",
    "    def forward(self, predictons, targets):\n",
    "        \"\"\"\n",
    "        損失関数の計算\n",
    "        \n",
    "        Parameters\n",
    "        ---------------\n",
    "        predictions : SSD netの訓練時の出力(tuple)\n",
    "            (loc=torch.Size([num_batch, 8732, 4]),\n",
    "            conf=torch.Size([num_batch, 8732, 21]), \n",
    "            dbox_list=torch.Size([8732, 4]))\n",
    "            \n",
    "        targets : [num_batch, num_objs, 5]\n",
    "            5は正解のアノテーション情報[xmin, ymin, xmax, ymax, label_ind]を示す\n",
    "            \n",
    "        Returns\n",
    "        ---------------\n",
    "        loss_l : Tensor\n",
    "            locの損失　　smoothL1Loss\n",
    "        loss_c : Tensor\n",
    "            confの損失　cross　entropy\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        # SSDのモデルの出力がtupleなのでここにバラす\n",
    "        loc_data, conf_data, dbox_list = predictions\n",
    "        \n",
    "        # 要素数を把握\n",
    "        num_batch = loc_data.size(0)   # ミニバッチのサイズ\n",
    "        num_dbox = loc_data.size(1)    # DBoxの数＝8732\n",
    "        num_classes = conf_data.size(2)  # クラス数＝２１\n",
    "        \n",
    "        # 損失の計算に使用するものを格納する変数を作る\n",
    "        # conf_t_label : 各DBoxに一番近い正解のBBoxのラベルを格納\n",
    "        # loc_t : 各DBoxに一番近い正解のBBoxの位置情報を格納させる\n",
    "        conf_t_label = torch.LongTensor(num_batch, num_dbox).to(self.device)  # 64-bit integer\n",
    "        loc_t = torch.Tensor(num_batch, num_dbox, 4).to(self.device)# 32-bit floating point\n",
    "        \n",
    "        # conf_t_label,　loc_tに\n",
    "        # DBoxと正解アノテーションtargetsをmatchさせた結果を上書きする\n",
    "        for idx in range(num_batch):   # ミニバッチでループ\n",
    "            \n",
    "            # 現在のミニバッチの正解アノテーションのBBoxトラベルを取得\n",
    "            truths = targets[idx][:, :, -1].to(self.device)   # BBox\n",
    "            lables = targets[idx][:,-1].to(self.device)\n",
    "            \n",
    "            # デフォルトボックスを新たな変数で用意\n",
    "            dbox = dbox_list.to(dself.evice)\n",
    "            \n",
    "            # match関数を実行しloc_t, conf_t_labelの内容を更新する\n",
    "            variance = [0.1, 0.2]\n",
    "            # variance : DBoxからBBoxに補正計算する際に使用する式の係数\n",
    "            match(self.jaccard_thresh, truths, dbox, variance, labels, loc_t, conf_t_label, idx)\n",
    "            \n",
    "        # -------\n",
    "        # 位置の損失：loss_l を計算\n",
    "        # SmoothL1Loss  ただし物体を発見したDBoxオフセットのみを計算\n",
    "        # -------\n",
    "        # 物体検出したBBoxを取り出すマスクを作成\n",
    "        pos_mask = conf_t_label > 0  # 背景以外\n",
    "        # pos_maskをloc_dataのサイズに変形\n",
    "        pos_idx = pos_mask.unsqeeze(pos_mask.dim()).expand_as(loc_data)\n",
    "        \n",
    "        # positive DBoxのloc_dataと教師データloc_tを取得\n",
    "        loc_p = loc_data[pos_idx].view(-1, 4)\n",
    "        loc_t = loc_t[pos_idx].view(-1, 4)\n",
    "        \n",
    "        # loc_p, loc_tを使って物体を発見したPositive DBoxのオフセット情報loc_tの損失を計算\n",
    "        loss_l = F.smooth_l1_loss(loc_p, loc_t, reduction='sum')\n",
    "        \n",
    "        # -------\n",
    "        # クラス予測の損失：loss_ｃ を計算\n",
    "        # Cross Entropy　Loss\n",
    "        # ただし背景クラスが正解であるDBoxが圧倒的に多いので、\n",
    "        # Hard Negative Miningを実施し、物体発見DBoxと背景クラスDBoxが1:3の比になるようにする\n",
    "        # 背景クラスDBoxと予測したもののうち、損失が小さいものはクラス予測の損失から除く\n",
    "        # -------\n",
    "        batch_conf = conf_data.view(-1, num_classes)\n",
    "        \n",
    "        # クラス予測の損失を関数を使って計算\n",
    "        # reduction = None　にして和を取らず、次元を潰さない\n",
    "        loss_c = F.cross_entropy(\n",
    "            batch_conf, conf_t_label.view(-1), reduction='none')\n",
    "        \n",
    "        # -------\n",
    "        # Hard Negative Mining で抽出するものを求めるマスクを作成\n",
    "        # -------\n",
    "        \n",
    "        # 物体発見したPositive DBoxの損失を０にする\n",
    "        num_pos = pos_mask.long().sum(1, keepdim=True)  # ミニバッチ毎の物体クラス予測の数\n",
    "        loss_c = loss_c.view(num_batch, -1)  # torch.Size([num_batch, 8732])\n",
    "        loss_c[pos_mask] = 0    # 物体を発見したDBoxは損失０とする\n",
    "        \n",
    "        # Hard Negative Minigを実施\n",
    "        _, loss_idx = loss_c.sort(1, descending=True)\n",
    "        _, idx_rand = loss_idx.sort(1)\n",
    "        \n",
    "        num_neg = torch.clamp(num_pos*self.negpos_ratio, max=num_dbox)\n",
    "        neg_mask = idx_rank < (num_neg).expand_as(idx_rank)\n",
    "        \n",
    "        # -------\n",
    "        # Negative DBoxのうちHarad Negative Miningで抽出するものを求めるマスクを作成\n",
    "        # -------\n",
    "        pos_idx_mask = pos_mask.unsqeeze(2).expand_as(conf_data)\n",
    "        neg_idx_mask = neg_mask.unsqeeze(2).expand_as(conf_data)\n",
    "        \n",
    "        conf_hnm = conf_data[(pos_idx_mask+neg_idx_mask).gt(0)].view(-1, num_classes)\n",
    "        \n",
    "        conf_t_label_hmn = conf_t_label[(pos_mask+neg_mask).gt(0)]\n",
    "        \n",
    "        # confidence の損失関数を計算\n",
    "        loss_c = F.cross_entropy(conf_hnm, conf_t_label_hnm, reduction='sum')\n",
    "        \n",
    "        # 物体を発見したBBoxの数N（全ミニバッチの合計）で損失を割り算\n",
    "        N = num_pos.sum()\n",
    "        loss_l /= N\n",
    "        loss_c /= N\n",
    "        \n",
    "        return loss_l, loss_c\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
