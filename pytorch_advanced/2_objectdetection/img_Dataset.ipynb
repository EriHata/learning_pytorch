{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習、検証の画像データとアノテーションデータへのファイルパスリストを作成する\n",
    "\n",
    "def make_datapath_list(rootpath):\n",
    "    \"\"\"\n",
    "    データへのパスを格納したリストを作成する\n",
    "    \n",
    "    Params:\n",
    "    -------------\n",
    "    rootpath : str\n",
    "        データフォルダへのパス\n",
    "    \n",
    "    Returns:\n",
    "    -------------\n",
    "    ret : train_img_list, train_anno_list, val_img_list, val_anno_list\n",
    "        データのへのパスを格納したリスト      \n",
    "    \"\"\"\n",
    "    \n",
    "    # 画像ファイルとアノテーションファイルへのパスのテンプレートを作成\n",
    "    imgpath_template = ops.join(rootpath, 'JPEGImages', '%s.jpg')　　　# テンプレートの書き方がわからない\n",
    "    annopath_tempate = ops.join(rootpath, 'Annotations', '%s.xml')\n",
    "    \n",
    "    # 訓練と検証、それぞれのファイルのID（ファイル名）を取得する\n",
    "    train_id_names  = ops.join(rootpath+'ImageSets/Main/train.txt')\n",
    "    val_id_names = ops.join(rootpaht+'ImageSets/Main/val.txt')\n",
    "    \n",
    "    # 訓練データの画像ファイルとアノテーションファイルへのパスのリストを作成\n",
    "    trian_img_list = list()\n",
    "    train_anno_list = list()\n",
    "    \n",
    "    for line in open(train_id_names):\n",
    "        file_id = line.strip()  # 空白スペースと改行を除去\n",
    "        img_path = (imgpath_template % file_id)      # 画像のパス  なぜタプルで囲む必要があるのか\n",
    "        anno_path = (annopath_tempate % file_id)   # アノテーションのパス\n",
    "        train_img_names.append(img_path)               # リストに追加\n",
    "        train_anno_names.append(anno_path)           # リストに追加\n",
    "    \n",
    "    # 検証データの画像ファイルとアノテーションファイルへのパスのリストを作成\n",
    "    val_img_list = list()\n",
    "    val_anno_list = list()\n",
    "    \n",
    "    for line in open(val_id_names):\n",
    "        file_id = line.strip()  # 空白スペースと改行を除去\n",
    "        img_path = (imgpath_template % file_id)      # 画像のパス\n",
    "        anno_path = (annopath_tempate % file_id)   # アノテーションのパス\n",
    "        val_img_names.append(img_path)               # リストに追加\n",
    "        val_anno_names.append(anno_path)           # リストに追加\n",
    "    \n",
    "    return  trian_img_list, train_anno_list, val_img_list, val_anno_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JPEGImages/000000.jpg\n"
     ]
    }
   ],
   "source": [
    "# template test\n",
    "test_path = osp.join('JPEGImages', '%s.jpg')\n",
    "file_id  = '000000'\n",
    "img_path = (test_path % file_id)  \n",
    "print(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ファイルパスのリストを作成\n",
    "rootpath = './data/VOCdevkit/VOC2012/'\n",
    "trian_img_list, train_anno_list, val_img_list, val_anno_list = make_datapath_list(rootpath)\n",
    "\n",
    "# 動作確認\n",
    "print(train_img_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'i', 'u', 'e', 'o']\n",
      "['a', 'i', 'u', 'e', 'o', 'ka', 'ki', 'ku', 'ke', 'ko']\n"
     ]
    }
   ],
   "source": [
    "# listにlist足したらどうなるのか\n",
    "ret = []\n",
    "a = ['a', 'i', 'u', 'e' ,'o']\n",
    "b = ['ka', 'ki', 'ku', 'ke' ,'ko']\n",
    "ret += a \n",
    "print(ret)\n",
    "ret += b\n",
    "print(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['a', 'i', 'u', 'e', 'o']]\n",
      "[['a', 'i', 'u', 'e', 'o'], ['ka', 'ki', 'ku', 'ke', 'ko']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([['a', 'i', 'u', 'e', 'o'],\n",
       "       ['ka', 'ki', 'ku', 'ke', 'ko']], dtype='<U2')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# listをlistで囲ってlistに足したらどうなるのか\n",
    "ret = []\n",
    "a = ['a', 'i', 'u', 'e' ,'o']\n",
    "b = ['ka', 'ki', 'ku', 'ke' ,'ko']\n",
    "ret += [a] \n",
    "print(ret)\n",
    "ret += [b]\n",
    "print(ret)\n",
    "\n",
    "# これをnumpyにしたら\n",
    "import numpy as np\n",
    "np.array(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XML形式のアノテーションデータをpythonのリスト形式に変換するクラス\n",
    "\n",
    "class Anno_xml2list(object):\n",
    "    \"\"\"\n",
    "    一枚の画像に対する「ｘml形式のアノテーションデータ」を画像サイズに規格化してからリスト形式に変換する\n",
    "    \n",
    "    Attributeｓ\n",
    "    -------------\n",
    "    classes : list\n",
    "        VOCのクラス名を格納したリスト\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, classes):\n",
    "        self.classes = classes\n",
    "        \n",
    "    def __call__(self, xml_path, width, hetig):\n",
    "        \"\"\"\n",
    "        一枚の画像に対する「ｘml形式のアノテーションデータ」を画像サイズに規格化してからリスト形式に変換する\n",
    "        \n",
    "        Params\n",
    "        -------------\n",
    "        xml_path : str\n",
    "            xmlファイルへのパス\n",
    "        width : int\n",
    "            対象画像の幅\n",
    "        height : int\n",
    "            対象画像の高さ\n",
    "            \n",
    "        Returns\n",
    "        -------------\n",
    "        ret : [[xmin, ymin, xmax, ymax, label_ind], ...]\n",
    "            物体のアノテーションデータを格納したリスト\n",
    "            画像内に存在する物体数分の要素を持つ\n",
    "            一つの画像につき５つの値が与えられている\n",
    "        \"\"\"\n",
    "        \n",
    "        # 画像内の全ての物体のアノテーションをこのリストに格納\n",
    "        ret = []\n",
    "        \n",
    "        # xmlファイルの読み込み\n",
    "        xml = ET.parse(xml_path).getroot()\n",
    "        \n",
    "        # 画像内にある物体(object)の数だけループする\n",
    "        for obj in xml.iter('object'):\n",
    "            # アノテーションで検知がdifficultに設定されているものを除外\n",
    "            difficult = int(obj.find('difficult').text)   # この書きかた分かってない　find()\n",
    "            if difficult == 1:\n",
    "                continue\n",
    "            \n",
    "            # 一つの物体に対するアノテーションを格納するリスト\n",
    "            bndbox = []\n",
    "            name = obj.find('name').text.lower().strip()  # 物体名\n",
    "            bbox = obj.find('bbox')                                      # バウンディングボックスの情報\n",
    "            \n",
    "            # アノテーションの xmin, ymin, xmax, ymax, label_ind を取得し、0-1に正規化\n",
    "            pts = ['xmin', 'ymin', 'xmax', 'ymax']\n",
    "            \n",
    "            for pt in (pts):\n",
    "                # なぜタプルで囲ったのか\n",
    "                # 原点が(1,1)なので(0,0)に修正\n",
    "                cur_pixel = int(bbox.find(pt).text) - 1\n",
    "                \n",
    "                # 幅、高さで規格化\n",
    "                if pt == 'xmin' or pt == 'xmax':       # x軸の方向のときは幅で割り算\n",
    "                    cur_pixel  /= width\n",
    "                else:                                                    # y軸のときは高さで割り算\n",
    "                    cur_pixel /= height\n",
    "                \n",
    "                bndbox.append(cur_pixel)\n",
    "                \n",
    "            # アノテーションのクラス名のindexを取得して追加\n",
    "            label_idx = self.classes.index(name)\n",
    "            bndbox.append(lable_idx)\n",
    "            \n",
    "            # res に[[xmin, ymin, xmax, ymax, label_ind]]を追加する\n",
    "            res += [bndbox]\n",
    "            \n",
    "        return np.array(ret)  # [[xmin, ymin, xmax, ymax, label_ind], ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anno_xml2listの動作確認\n",
    "voc_classes = ['aeroplane', 'bicycle', 'bird', 'boat', \n",
    "               'bottle', 'bus', 'car', 'cat', 'chair', 'cow', \n",
    "               'diningtable', 'dog', 'horse', 'motorbike', \n",
    "               'person', 'pottedplant', 'sheep', 'sofa', \n",
    "              'train', 'tvmonitor']\n",
    "\n",
    "# ここで__init__\n",
    "transform_anno = Anno_xml2list(voc_classes)\n",
    "\n",
    "# 画像の読み込み　OpenCVを使用\n",
    "ind = 1\n",
    "image_file_path = val_img_list[ind]\n",
    "img = cv2.imread(image_file_path)   # 高さ、幅、色RGB\n",
    "height, width, channels = img.shape   # 画像サイズの取得\n",
    "\n",
    "# アノテーションをリストで表示\n",
    "# ここで__call__\n",
    "transform_anno(val_anno_list[ind], width, height)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
