{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ネットワークモデルの実装、順伝播関数の実装\n",
    "SSDのネットワークモデルと順伝播forward関数を実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 目標\n",
    "### ネットワークモデル\n",
    "1. SSDのネットワークを構築している４つのモジュールを把握\n",
    "2. SSDのネットワークモデルを作成できるようになる\n",
    "3. SSDで使用する様々な大きさのDafaultBoxの実装方法を理解する\n",
    "\n",
    "### 順伝播\n",
    "1. Non-Maximum Suppressionを理解\n",
    "2. SSDの推論時に使用するDetectクラスの順伝播を理解する\n",
    "3. SSDの順伝播を実装できるようにする"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "from torch.autograd import Function\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from math import sqrt\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## vggモジュールを実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModuleList(\n",
      "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (3): ReLU(inplace=True)\n",
      "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (6): ReLU(inplace=True)\n",
      "  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (8): ReLU(inplace=True)\n",
      "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (11): ReLU(inplace=True)\n",
      "  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (13): ReLU(inplace=True)\n",
      "  (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (15): ReLU(inplace=True)\n",
      "  (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "  (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (18): ReLU(inplace=True)\n",
      "  (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (20): ReLU(inplace=True)\n",
      "  (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (22): ReLU(inplace=True)\n",
      "  (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (25): ReLU(inplace=True)\n",
      "  (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (27): ReLU(inplace=True)\n",
      "  (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (29): ReLU(inplace=True)\n",
      "  (30): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "  (31): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6))\n",
      "  (32): ReLU(inplace=True)\n",
      "  (33): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (34): ReLU(inplace=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 34層に渡るvggモジュールの作成\n",
    "# 各層の設定をリスト(cfg)で保持してfor文回してlayerを作っていく\n",
    "\n",
    "def make_vgg():\n",
    "    layers = []\n",
    "    in_channels = 3   # 色チャネル情報\n",
    "    \n",
    "    # vggモジュールで使用する畳み込みそうやマックスプーリングのチャネル数\n",
    "    cfg = [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'MC', 512, 512, 512, 'M', 512, 512, 512]\n",
    "    \n",
    "    for v in cfg:\n",
    "        if v == 'M':\n",
    "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "        elif v == 'MC':\n",
    "            # ceilは出力shapeの計算で、計算結果(float)に対して、切り上げ整数にするモード\n",
    "            # defaultでは出力サイズを計算結果に対して切り下げて整数にするfloorモードになっている\n",
    "            layers += [nn.MaxPool2d(kernel_size=2, stride=2, ceil_mode=True)]\n",
    "        else:\n",
    "            # pooling以外であればconv層\n",
    "            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
    "            layers += [conv2d, nn.ReLU(inplace=True)]\n",
    "            in_channels = v     # 次のconv用に更新しておく\n",
    "            \n",
    "    # 最後だけ変則的な設定なのでfor文の中に入れていない      \n",
    "    pool5 = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
    "    conv6 = nn.Conv2d(512, 1024, kernel_size=3, padding=6, dilation=6)\n",
    "    conv7 = nn.Conv2d(1024, 1024, kernel_size=1)\n",
    "    layers += [pool5, conv6, nn.ReLU(inplace=True), conv7, nn.ReLU(inplace=True)]\n",
    "    \n",
    "    return nn.ModuleList(layers)\n",
    "\n",
    "\n",
    "# 動作確認\n",
    "vgg_test = make_vgg()\n",
    "print(vgg_test)\n",
    "    \n",
    "# OK  34層のvggネットワークができている        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4]\n",
      "[[0, 0, 0], [1, 1, 1], [2, 2, 2], [3, 3, 3], [4, 4, 4]]\n",
      "[0, 0, 0, 1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4]\n"
     ]
    }
   ],
   "source": [
    "# リストにリストを足していくとどうなるか  これを上のlayerでやっている\n",
    "l1 = []\n",
    "tmp_list = []\n",
    "for i in range(5):\n",
    "    tmp_list = [i, i, i]\n",
    "    l1 += tmp_list\n",
    "print(l1)\n",
    "\n",
    "# リストにリストをappendしていくとどうなるか\n",
    "l1 = []\n",
    "tmp_list = []\n",
    "for i in range(5):\n",
    "    tmp_list = [i, i, i]\n",
    "    l1.append(tmp_list)\n",
    "print(l1)\n",
    "\n",
    "# リストにリストをextendしていくとどうなるか\n",
    "l1 = []\n",
    "tmp_list = []\n",
    "for i in range(5):\n",
    "    tmp_list = [i, i, i]\n",
    "    l1.extend(tmp_list)\n",
    "print(l1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extraモジュールの実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModuleList(\n",
      "  (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (2): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (4): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (5): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (6): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 8層のextraモジュールを作成\n",
    "# source2を入力として、source3-6を出力する　書くsourceは特徴マップの大きさが違う\n",
    "# 活性化関数のReLUはssdモデルのforwardで用意することにして、extraモジュールでは実装しない\n",
    "\n",
    "def make_extras():\n",
    "    layers = []\n",
    "    in_channels = 1024   # vggモジュールから出力されたsource2の画像チャネル数\n",
    "    \n",
    "    # extraモジュールの畳み込み層のチャネル数を設定するconfig\n",
    "    cfg = [256, 512, 128, 256, 128, 256, 128, 256]\n",
    "    \n",
    "    # 細かい設定が異なるのでfor文でまとめられない\n",
    "    layers += [nn.Conv2d(in_channels, cfg[0], kernel_size=(1))]\n",
    "    layers += [nn.Conv2d(cfg[0], cfg[1], kernel_size=(3), stride=2, padding=1)]\n",
    "    layers += [nn.Conv2d(cfg[1], cfg[2], kernel_size=(1))]\n",
    "    layers += [nn.Conv2d(cfg[2], cfg[3], kernel_size=(3), stride=2, padding=1)]\n",
    "    layers += [nn.Conv2d(cfg[3], cfg[4], kernel_size=(1))]\n",
    "    layers += [nn.Conv2d(cfg[4], cfg[5], kernel_size=(3))]\n",
    "    layers += [nn.Conv2d(cfg[5], cfg[6], kernel_size=(1))]\n",
    "    layers += [nn.Conv2d(cfg[6], cfg[7], kernel_size=(3))]\n",
    "    \n",
    "    return nn.ModuleList(layers)\n",
    "\n",
    "# 動作確認\n",
    "extras_test = make_extras()\n",
    "print(extras_test)\n",
    "\n",
    "# OK  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## locモジュールとconfモジュールの実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModuleList(\n",
      "  (0): Conv2d(512, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): Conv2d(1024, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (2): Conv2d(512, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (3): Conv2d(256, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (4): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (5): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n",
      "ModuleList(\n",
      "  (0): Conv2d(512, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (1): Conv2d(1024, 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (2): Conv2d(512, 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (3): Conv2d(256, 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (4): Conv2d(256, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (5): Conv2d(256, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# default boxのoffsetを出力するloc_layers\n",
    "# default boxに対する各クラスの信頼度confidenceを出力するconf_layersを作成\n",
    "# どちらのモジュールもsource1-6に対し各々convを噛ませている\n",
    "# ２０分類＋背景１の２１つのクラスに分類する\n",
    "\n",
    "def make_loc_conf(num_classes=21, bbox_aspect_num=[4, 6, 6, 6, 4, 4, 4]):\n",
    "    \"\"\"\n",
    "    num_classes: int\n",
    "        分類するクラス数（物体２０分類＋背景１分類）\n",
    "    \n",
    "    bbox_aspect_num: source1-6に対するdefault boxの種類の数\n",
    "    \"\"\"\n",
    "    \n",
    "    loc_layers = []\n",
    "    conf_layers = []\n",
    "    \n",
    "    # vggの２２層目、conv4_3(source1)に対する畳み込み層\n",
    "    loc_layers += [nn.Conv2d(512, bbox_aspect_num[0]*4, kernel_size=3, padding=1)]\n",
    "    conf_layers += [nn.Conv2d(512, bbox_aspect_num[0]*num_classes, kernel_size=3, padding=1)]\n",
    "    \n",
    "    # vggの最終層(source2)に対する畳み込み層\n",
    "    loc_layers += [nn.Conv2d(1024, bbox_aspect_num[1]*4, kernel_size=3, padding=1)]\n",
    "    conf_layers += [nn.Conv2d(1024, bbox_aspect_num[1]*num_classes, kernel_size=3, padding=1)]\n",
    "    \n",
    "    # extraの(source3)に対する畳み込み層\n",
    "    loc_layers += [nn.Conv2d(512, bbox_aspect_num[2]*4, kernel_size=3, padding=1)]\n",
    "    conf_layers += [nn.Conv2d(512, bbox_aspect_num[2]*num_classes, kernel_size=3, padding=1)]\n",
    "    \n",
    "    # extraの(source4)に対する畳み込み層\n",
    "    loc_layers += [nn.Conv2d(256, bbox_aspect_num[3]*4, kernel_size=3, padding=1)]\n",
    "    conf_layers += [nn.Conv2d(256, bbox_aspect_num[3]*num_classes, kernel_size=3, padding=1)]\n",
    "    \n",
    "    # extraの(source5)に対する畳み込み層\n",
    "    loc_layers += [nn.Conv2d(256, bbox_aspect_num[4]*4, kernel_size=3, padding=1)]\n",
    "    conf_layers += [nn.Conv2d(256, bbox_aspect_num[4]*num_classes, kernel_size=3, padding=1)]\n",
    "    \n",
    "    # extraの(source6)に対する畳み込み層\n",
    "    loc_layers += [nn.Conv2d(256, bbox_aspect_num[5]*4, kernel_size=3, padding=1)]\n",
    "    conf_layers += [nn.Conv2d(256, bbox_aspect_num[5]*num_classes, kernel_size=3, padding=1)]\n",
    "    \n",
    "    return nn.ModuleList(loc_layers), nn.ModuleList(conf_layers)\n",
    "\n",
    "\n",
    "# 動作確認\n",
    "loc_test, conf_test = make_loc_conf()\n",
    "print(loc_test)\n",
    "print(conf_test)\n",
    "\n",
    "#  OK  出力したい変数分のoutputになっている\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L2Norm層の実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convC4_3からの出力をscale=20のL2Normで正規化する層\n",
    "class L2Norm(nn.Module):\n",
    "    def __init__(self, input_channels=512, scale=20):\n",
    "        super(L2Norm, self).__init__()   #  親クラスのコンストラクタ実行\n",
    "        self.weight = nn.Parameter(torch.Tensor(input_channels))\n",
    "        self.scale = scale                # 係数weightの初期値として設定する値\n",
    "        self.reset_parameters()   # parameterの初期化\n",
    "        self.eps = 1e-10\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        \"\"\"\n",
    "        結合パラメータを大きさscaleの値にする初期化を実行\n",
    "        \"\"\"\n",
    "        init.constant_(self.weight, self.scale)    # weightの値が全てscaleになる\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        38x38の特徴量に対して５１２チャネルに渡って二乗和のルートを求めた38x38この値を使用し、\n",
    "        各特徴量を正規化してから係数を掛け算する層\n",
    "        \"\"\"\n",
    "        # 各チャネルにおける３８ｘ３８個の特徴量のチャネル方向の二乗和を計算し、ルートを求め割り算して正規化する\n",
    "        # normのテンソルサイズはtorch.Size([batch_num, 1, 38, 38])になる\n",
    "        norm = x.pow(2).sum(dim=1, keepdim=True).sqrt() + self.eps  # 0除算を防ぐためのeps\n",
    "        x = torch.div(x, norm)\n",
    "        \n",
    "        # 係数をかける。係数を書くチャネルごとに一つで512この係数をもつ\n",
    "        # self.weightのテンソルサイズはtorch.Size([512])なので\n",
    "        # torch.Size([batch_num, 512, 38, 38])まで変形する\n",
    "        weights = self.weight.unsqueeze(0).unsqueeze(2).unsqueeze(3).expand_as(x)  # unsqueeze : 次元を増やす\n",
    "        out = weights * x\n",
    "        \n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## default boxの実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default boxを出力するクラス\n",
    "# cfgに結構いろんな設定をしておくようである\n",
    "class DBox(object):\n",
    "    def __init__(self, cfg):\n",
    "        super(DBox, self).__init__()    # 親クラスのコンストラクタを実行するときにクラスの名前入れなくてもいいはず\n",
    "        \n",
    "        # 初期設定\n",
    "        self.image_size = cfg['input_size']  # 画像サイズの300\n",
    "        # [38, 19, ...]各sourceの特徴マップのサイズ\n",
    "        self.feature_maps = cfg['feature_maps']\n",
    "        self.num_priors = len(cfg['feature_maps'])   # source の個数＝６\n",
    "        self.steps = cfg['steps']  # [8, 16, ...] DBoxのピクセルサイズ\n",
    "        self.min_sizes = cfg['min_sizes']  # [30, 60, ...] 小さい方の正方形のDBoxのピクセルサイズ\n",
    "        self.max_sizes = cfg['max_sizes']  # [60, 111, ...] 大きい方の正方形のDBoxのピクセルサイズ\n",
    "        self.aspect_ratios = cfg['aspect_ratios']  # 長方形のDBoxのアスペクト比\n",
    "        \n",
    "    def make_dbox_list(self):\n",
    "        \"\"\"\n",
    "        DBoxを作成する\n",
    "        \"\"\"\n",
    "        mean = []\n",
    "        # 'feature_maps' : [38, 19, 10, 5, 3, 1]\n",
    "        for k, f in enumerate(self.feature_maps):\n",
    "            for i, j in product(range(f), repeat=2):  # fまで数で2ペアの組み合わせを作る f_P_2個\n",
    "                # 特徴量の画像サイズ\n",
    "                # 300 / 'steps' : [8, 16, 32, 64, 100, 300],\n",
    "                f_k = self.image_size / self.steps[k]\n",
    "                \n",
    "                # DBoxの中心座標x, y ただし。０−１で規格化している\n",
    "                cx = (j+0.5) / f_k\n",
    "                cy = (i+0.5) / f_k\n",
    "                \n",
    "                # アスペクト比１の小さいDBox[cx, cy, width, height]\n",
    "                # 'min_sizes' : [30, 60, 111, 162, 213, 264]\n",
    "                s_k = self.min_sizes[k] / self.image_size\n",
    "                mean += [cx, cy, s_k, s_k]\n",
    "                \n",
    "                # アスペクト比１の大きいDBox [cx, cy, width, height]\n",
    "                # 'max_sizes' : [60, 111, 162, 213, 264, 315],\n",
    "                s_k_prime = sqrt(s_k*(self.max_sizes[k]/self.image_size))\n",
    "                mean += [cx, cy, s_k_prime, s_k_prime]\n",
    "                \n",
    "                # その他のアスペクト比のdefbox [cx, cy, width, height]\n",
    "                for ar in self.aspect_ratios[k]:\n",
    "                    mean += [cx, cy, s_k*sqrt(ar), s_k/sqrt(ar)]\n",
    "                    mean += [cx, cy, s_k/sqrt(ar), s_k*sqrt(ar)]\n",
    "                \n",
    "        # DBoxをlist -> tensorに変換 torch.Size([8732, 4])\n",
    "        output = torch.Tensor(mean).view(-1, 4)\n",
    "        \n",
    "        # DBoxが画像の外にはみ出るのを防ぐため、大きさを最小０，最大１にする\n",
    "        output.clamp_(max=1, min=0)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.141421</td>\n",
       "      <td>0.141421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.141421</td>\n",
       "      <td>0.070711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.070711</td>\n",
       "      <td>0.141421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8727</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.502046</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8728</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.880000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8729</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.961249</td>\n",
       "      <td>0.961249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8730</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.622254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8731</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.622254</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8732 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3\n",
       "0     0.013333  0.013333  0.100000  0.100000\n",
       "1     0.013333  0.013333  0.141421  0.141421\n",
       "2     0.013333  0.013333  0.141421  0.070711\n",
       "3     0.013333  0.013333  0.070711  0.141421\n",
       "4     0.040000  0.013333  0.100000  0.100000\n",
       "...        ...       ...       ...       ...\n",
       "8727  0.833333  0.833333  0.502046  1.000000\n",
       "8728  0.500000  0.500000  0.880000  0.880000\n",
       "8729  0.500000  0.500000  0.961249  0.961249\n",
       "8730  0.500000  0.500000  1.000000  0.622254\n",
       "8731  0.500000  0.500000  0.622254  1.000000\n",
       "\n",
       "[8732 rows x 4 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DBoxの動作の確認\n",
    "\n",
    "# ssd300の設定\n",
    "ssd_cfg = {\n",
    "    'num_classes' : 21,                                                                   #　背景クラスを含めた合計クラス数\n",
    "    'input_size' : 300,                                                                     # 画像の入力サイズ\n",
    "    'bbox_aspect_num' : [4, 6, 6, 6, 4, 4],                                  # 出力するDBoxのアスペクト比の種類\n",
    "    'feature_maps' : [38, 19, 10, 5, 3, 1],                                   # 各source（feature map）の画像サイズ　\n",
    "    'steps' : [8, 16, 32, 64, 100, 300],                                        # DBOXの大きさを決める\n",
    "    'min_sizes' : [30, 60, 111, 162, 213, 264],                         # \n",
    "    'max_sizes' : [60, 111, 162, 213, 264, 315],\n",
    "    'aspect_ratios' : [[2], [2, 3], [2, 3], [2, 3], [2], [2]],\n",
    "}\n",
    "\n",
    "# DBox作成\n",
    "dbox = DBox(ssd_cfg)\n",
    "dbox_list = dbox.make_dbox_list()\n",
    "\n",
    "# DBoxの出力を確認する\n",
    "pd.DataFrame(dbox_list.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SSDクラスの実装\n",
    "ここまで作成したモジュールをまとめてssdクラスを実装する\n",
    "pytorchのネットワーク層クラスのnn.Moduleを継承\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSD(\n",
      "  (vgg): ModuleList(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
      "    (31): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6))\n",
      "    (32): ReLU(inplace=True)\n",
      "    (33): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (34): ReLU(inplace=True)\n",
      "  )\n",
      "  (extras): ModuleList(\n",
      "    (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (2): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (4): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (5): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (6): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "  )\n",
      "  (L2Norm): L2Norm()\n",
      "  (loc): ModuleList(\n",
      "    (0): Conv2d(512, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): Conv2d(1024, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (2): Conv2d(512, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): Conv2d(256, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      "  (conf): ModuleList(\n",
      "    (0): Conv2d(512, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): Conv2d(1024, 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (2): Conv2d(512, 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): Conv2d(256, 126, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): Conv2d(256, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): Conv2d(256, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# ssdクラスを作成\n",
    "class SSD(nn.Module):\n",
    "    \n",
    "    def __init__(self, phase, cfg):\n",
    "        super(SSD, self).__init__()  # 親クラスのコンストラクタを実行\n",
    "        \n",
    "        self.phase = phase   # 'train' or 'inference' を指定\n",
    "        self.num_classes = cfg['num_classes']\n",
    "        \n",
    "        # ssdのネットワークを作る\n",
    "        self.vgg = make_vgg()\n",
    "        self.extras = make_extras()\n",
    "        self.L2Norm = L2Norm()\n",
    "        self.loc, self.conf = make_loc_conf(\n",
    "            cfg['num_classes'], cfg['bbox_aspect_num'])\n",
    "        \n",
    "        # DBox作成\n",
    "        dbox = DBox(cfg)\n",
    "        self.dbox_list = dbox.make_dbox_list()\n",
    "        \n",
    "        # 推論時はDetectクラスを用意\n",
    "        if phase == 'inference':\n",
    "            self.detect = Detect()\n",
    "\n",
    "# 動作確認\n",
    "ssd_test = SSD(phase='train', cfg=ssd_cfg)\n",
    "print(ssd_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 順伝播関数の実装\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 目標\n",
    "\n",
    "### 順伝播\n",
    "1. Non-Maximum Suppressionを理解\n",
    "2. SSDの推論時に使用するDetectクラスの順伝播を理解する\n",
    "3. SSDの順伝播を実装できるようにする"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## decode関数を実装\n",
    "dbox = (cx_d, cy_d, w_d, h_d)と、loc =(Δcx, Δcy, Δw, Δh)を使用してbboxの座標を取得する関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(loc, dbox_list):\n",
    "    \"\"\"\n",
    "    オフセット情報を使ってDBoxをBBoxに変換する\n",
    "    \n",
    "    Parameters\n",
    "    ----------------\n",
    "    loc: [8732, 4]\n",
    "        ssdモデルで推論したオフセット情報\n",
    "    dbox_list: [8732, 4]\n",
    "        DBoxの情報\n",
    "        \n",
    "    Returns\n",
    "    ----------------\n",
    "    boxes: [xmin, ymin, xmax, ymax]\n",
    "        BBoxの情報\n",
    "    \"\"\"\n",
    "    \n",
    "    # DBoxは[cx,, cy, width, height]で格納されている\n",
    "    # locも[Δcx, Δcy, Δw, Δh]で格納されている\n",
    "    \n",
    "    # オフセット情報からBBoxを求める\n",
    "    boxes = torch.cat((\n",
    "        dbox_list[:, :2]+0.1*loc[:, :2]*dbox_list[:, 2:],\n",
    "        dbos_list[:, 2:]*torch.exp(0.2*loc[:, 2:])), dim=1)      # 2列ずつ計算して最後cat, dim=1で横につなげる\n",
    "        \n",
    "    # boxesのサイズは[8732, 4]\n",
    "    # bboxの座標を[cx, cy, width, height] -> [xmin, ymin, xmax, ymax]に変換\n",
    "    boxes[:, :2] -= boxes[:, 2:] / 2   # xmin, yminに変換\n",
    "    boxes[:, 2:] += boxes[:, :2]        # xmax, ymaxに変換\n",
    "    \n",
    "    return boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 3, 4])\n",
      "torch.Size([2, 9, 4])\n",
      "torch.Size([2, 3, 12])\n"
     ]
    }
   ],
   "source": [
    "# torch.catのデモ\n",
    "input1 = torch.randn(2,3,4)\n",
    "input2 = torch.randn(2,3,4)\n",
    "input3 = torch.randn(2,3,4)\n",
    "input_list = [input1, input2, input3]\n",
    "\n",
    "output1 =  torch.cat(input_list, dim=0)\n",
    "print(output1.size())\n",
    "output2 =  torch.cat(input_list, dim=1)\n",
    "print(output2.size())\n",
    "output3 =  torch.cat(input_list, dim=2)\n",
    "print(output3.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9, 3, 4])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "invalid argument 0: Sizes of tensors must match except in dimension 1. Got 2 and 5 in dimension 0 at /Users/distiller/project/conda/conda-bld/pytorch_1579022061893/work/aten/src/TH/generic/THTensor.cpp:612",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-d6f01bb0d89c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0moutput1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0moutput2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0moutput3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: invalid argument 0: Sizes of tensors must match except in dimension 1. Got 2 and 5 in dimension 0 at /Users/distiller/project/conda/conda-bld/pytorch_1579022061893/work/aten/src/TH/generic/THTensor.cpp:612"
     ]
    }
   ],
   "source": [
    "# わざとエラーになるようにしてあるセル\n",
    "input1 = torch.randn(2, 3, 4)\n",
    "input2 = torch.randn(2, 3, 4)\n",
    "input3 = torch.randn(5, 3, 4)\n",
    "input_list = [input1, input2, input3]\n",
    "\n",
    "\n",
    "output1 = torch.cat(input_list, dim=0)\n",
    "print(output1.size())\n",
    "output2 = torch.cat(input_list, dim=1)  # error  dim=0のshapeがあっていないから\n",
    "print(output2.size()) \n",
    "output3 = torch.cat(input_list, dim=2)　　# error  dim=0のshapeがあっていないから\n",
    "print(output3.size()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-Maximum Supressionを行う関数を実装\n",
    "同じ物体に対する複数のBBoxの重複を確信度が最も高いもののみを残し、他のBBoxは消去する操作 = Non-Maximum Supression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nm_supression(boxes, scores, overlap=0.45, top_k=200):\n",
    "    \"\"\"\n",
    "    Non-Maximum Supressionを行う関数\n",
    "    boxesの内被りすぎ（overlap以上）のBBoxを削除する\n",
    "    \n",
    "    Parameters\n",
    "    ----------------\n",
    "    boxes : [確信度閾値（０．０１）を超えたBBox数, 4]\n",
    "        4は[xmin, ymin, xmax, ymax]の４つ\n",
    "        BBox情報\n",
    "    scores :  [確信度閾値（０．０１）を超えたBBox数]\n",
    "        conf情報\n",
    "    overlap : float\n",
    "        BBoxがかぶっているかどうかを判定する閾値\n",
    "    top_k : \n",
    "        \n",
    "    Returns\n",
    "    ----------------\n",
    "    keep : list\n",
    "        confの降順にnmsを通過したindexが格納\n",
    "    count : int\n",
    "        nmsを通過したBBoxの数\n",
    "    \"\"\"\n",
    "    # scoresの型確認\n",
    "    print(type(scores))\n",
    "    \n",
    "    # return の雛形を作成\n",
    "    count = 0\n",
    "    keep = scores.new(scores.size(0)).zero_().long()\n",
    "    \n",
    "    # keep : torch.Size([確信度閾値を超えたBBox数])、要素は全部０\n",
    "    \n",
    "    # 各BBoxの面積areaを計算\n",
    "    x1 = boxes[:, 0]    # xmin\n",
    "    y1 = boxes[:, 1]    # ymin\n",
    "    x2 = boxes[:, 2]    # xmax\n",
    "    y2 = boxes[:, 3]    # ymax\n",
    "    area = torch.mul(x2-x1, y2-y1)\n",
    "    \n",
    "    # boxesをコピーする。後でBBoxのかぶり度合いIOUの計算に使用する際の雛形(template)として使う\n",
    "    tmp_x1 = boxes.new()\n",
    "    tmp_y1 = boxes.new()\n",
    "    tmp_x2 = boxes.new()\n",
    "    tmp_y2 = boxes.new()\n",
    "    tmp_w = boxes.new()\n",
    "    tmp_h = boxes.new()\n",
    "    \n",
    "    # scoreを昇順に並び替える\n",
    "    v, idx = scores.sort(0)\n",
    "    \n",
    "    # 上位top_k（２００）個のBBoxのindexを取り出す\n",
    "    # 200個なかったときに out of rangeにならないのだろうか　ならなかった\n",
    "    idx = idx[-top_k:]\n",
    "    \n",
    "    # idxの要素が0でない限りループする\n",
    "    while idx.numel() > 0:\n",
    "        i = idx[-1]  # 現在のconfの最大のindexをiにする\n",
    "        \n",
    "        # keepの現在の最後にconfの最大のindexを格納する\n",
    "        # このindexのBBoxと被りが大きいBBoxを以降で消去する\n",
    "        keep[count] = i\n",
    "        count += 1\n",
    "        \n",
    "        # 最後のループになったときはループを抜ける\n",
    "        if idx.size(0) == 1:\n",
    "            break\n",
    "        \n",
    "        # 現在のconf最大のindexをkeepに格納したいのでidxを一つ減らす\n",
    "        idx = idx[:-1]\n",
    "        \n",
    "        # -----------------\n",
    "        # これからkeepに格納したBBoxと被りの大きいBBoxを抽出して除去する\n",
    "        # -----------------\n",
    "        # 一つ減らしたidxまでのBBoxを、outに指定した変数として作成する\n",
    "        torch.index_select(x1, 0, idx, out=tmp_x1)\n",
    "        torch.index_select(y1, 0, idx, out=tmp_y1)\n",
    "        torch.index_select(x2, 0, idx, out=tmp_x2)\n",
    "        torch.index_select(y2, 0, idx, out=tmp_y2)\n",
    "        \n",
    "        # 全てのBBOxに対して、現在のBBox=indexがiと被って居る値までに設定（clamp）\n",
    "        tmp_x1 = torch.clamp(tmp_x1, min=x1[i])\n",
    "        tmp_y1 = torch.clamp(tmp_y1, min=y1[i])\n",
    "        tmp_x2 = torch.clamp(tmp_x2, min=x2[i])\n",
    "        tmp_y2 = torch.clamp(tmp_y2, min=y2[i])\n",
    "        \n",
    "        # wとhのテンソルサイズをindexを一つ減らしたものにする\n",
    "        tmp_w.resize_as_(tmp_x2)\n",
    "        tmp_h.resize_as_(tmp_y2)\n",
    "        \n",
    "        # clampした状態でのBBoxの幅と高さを求める\n",
    "        tmp_w = tmp_x2 - tmp_x1\n",
    "        tmp_h = tmp_y2 - tmp_y1\n",
    "        \n",
    "        # 幅や高さが負になっているものは0にする\n",
    "        tmp_w = torch.clamp(tmp_w, min=0.0)\n",
    "        tmp_h = torch.clamp(tmp_h, min=0.0)\n",
    "        \n",
    "        # clampされた状態での面積を求める\n",
    "        inter = tmp_w * tmp_h\n",
    "        \n",
    "        # IoU = intersect部分　/ (area(a) + area(b) - intersect部分)の計算\n",
    "        # BBox同士の論理積　/ BBox同士の論理和\n",
    "        rem_areas = torch.index_select(area, 0, idx)   # 各BBoxの元の面積\n",
    "        union = (rem_areas - inter) + area[i]  # 2つのエリアの和(OR)の面積\n",
    "        IoU = inter / union\n",
    "        \n",
    "        # IoUがoverlapより小さいidxのみ残す\n",
    "        idx = idx[IoU.le(overlap)]   # le : Less than equal to\n",
    "        \n",
    "    # whileのループが抜けたら終了\n",
    "    \n",
    "    return keep, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute 'new'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-e90dd0cf108e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# torch.new()の確認\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch' has no attribute 'new'"
     ]
    }
   ],
   "source": [
    "# torch.new()の確認\n",
    "a = torch.new((3, 2)).zero_()\n",
    "# tensor.new()らしい"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.1850,  0.2771,  0.7181, -0.6247,  0.1221, -0.2196],\n",
      "        [ 0.4402, -0.3734, -0.7193, -0.7542,  0.3715, -0.4340],\n",
      "        [ 0.7251,  0.5971,  0.6088,  0.9716,  0.9566,  1.2273],\n",
      "        [ 1.5245,  2.1797, -0.4631, -1.1362, -1.7648,  0.1946]])\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "# torch.numel()の確認\n",
    "# 入力したtensorの全要素数を返す\n",
    "a = torch.randn(4, 6)\n",
    "print(a)\n",
    "\n",
    "out = torch.numel(a)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1,  4,  9, 16])\n",
      "tensor([ 1,  4,  9, 16])\n"
     ]
    }
   ],
   "source": [
    "# torch.mulの確認\n",
    "a = torch.arange(1,5,1)\n",
    "b = torch.arange(1,5,1)\n",
    "print(a*b)\n",
    "print(torch.mul(a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]\n",
      "[]\n",
      "[]\n",
      "[16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1]\n",
      "[16, 15, 14, 13, 12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1]\n"
     ]
    }
   ],
   "source": [
    "# out of rangeにならないか確認\n",
    "a = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16]  # len = 16\n",
    "a = a[-20:]\n",
    "print(a)\n",
    "b = a[:20]\n",
    "print(b)\n",
    "# 後ろからでも前からでもならなかった\n",
    "\n",
    "# 降順にしたいときはステップで指定する　 うまくいかなかった\n",
    "a = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16]\n",
    "a = a[-20::-1]\n",
    "print(a)\n",
    "b = a[:20:-1]\n",
    "print(b)\n",
    "\n",
    "# うまくいった\n",
    "a = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16]\n",
    "a = a[:-20:-1]\n",
    "print(a)\n",
    "a = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16]\n",
    "b = a[20::-1]\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.clampの確認\n",
    "# 最大値、最小値を指定の値で抑える"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.index_selectの確認"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detectクラスの実装\n",
    "推論時の最後にDetectクラスを使って（batch_num, 21, 200, 5）の出力テンソルを作成する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Detect(Function):\n",
    "    \n",
    "    def __init__(self, conf_thresh=0.01, top_k=200, nms_thresh=0.45):\n",
    "        self.softmax = nn.Softmax(dim=-1)  # confをソフトマックス関数で正規化するため\n",
    "        self.conf_thresh = conf_thresh         # confがconf_thresh=0.01より高いDBoxのみをあつかう\n",
    "        self.top_k = top_k                               # nm_supressionでconfの高いtop_k個を計算に使用する\n",
    "        self.nms_thresh = nms_thresh          # nm_supressionでIoUがnms_thresh=0.45より大きいと同一物体へのBBoxとみなす\n",
    "        \n",
    "    def forward(self, loc_data, conf_data, dbox_list):\n",
    "        \"\"\"\n",
    "        順伝播の計算を実行する\n",
    "        \n",
    "        Parameters\n",
    "        ----------------\n",
    "        loc_data : [batch_num, 8732, 4]\n",
    "            オフセット情報\n",
    "        conf_data : [batch_num, 8732, num_classes]\n",
    "            検出の確信度\n",
    "        dbox_list : [8732, 4]\n",
    "            DBoxの情報\n",
    "        \n",
    "        Returns\n",
    "        ----------------\n",
    "        output : torch.Size([batch_num, 21, 200, 5])\n",
    "            [batch_num, クラス, confのtop200, BBoxの情報]     なんで５なんだろう\n",
    "        \"\"\"\n",
    "        \n",
    "        # 各サイズを取得\n",
    "        num_batch = loc_data.size(0)\n",
    "        num_dbox = loc_data.size(1)\n",
    "        num_classes = conf_data(2)\n",
    "        \n",
    "        # confはsoftmaxをかまして正規化\n",
    "        conf_data = self.softmax(conf_data)\n",
    "        \n",
    "        # 出力の型を作成。テンソルサイズは[mini_batch数、21, 200, 5]\n",
    "        # 一旦０埋めで形だけ作ってしまう\n",
    "        output = torch.zeros(num_batch, num_classes, self.top_k, 5)\n",
    "        \n",
    "        # conf_dataを [batch_num, 8732, num_classes] -> [batch_num, num_classes, 8732]\n",
    "        conf_preds = conf_data.transpose(2,1)\n",
    "        \n",
    "        # ミニバッチごとのループ\n",
    "        for i in range(num_batch):\n",
    "                \n",
    "                # 1. loc（オフセット情報）とdbox_list(Default Boxの形と座標をまとめたもの)から修正したBBox[xmin, ymin, xmax, ymax]を求める\n",
    "                decoded_boxes = decode(loc_data[i], dbox_list)\n",
    "                \n",
    "                # confのコピーを作成  どうしてcloneするのか\n",
    "                conf_scores = conf_preds[i].clone     # [num_classes, 8732]になっている\n",
    "                \n",
    "                # 画像クラスごとのループ（背景クラスのindexである０は計算せず、index=1から）\n",
    "                for cl in range(1, num_classes):\n",
    "                    \n",
    "                    # 2.confの閾値を超えたBBoxを取り出す\n",
    "                    # confの閾値を超えているかのマスクを作成し閾値を超えたconfのインデックスをc_maskとして取得\n",
    "                    c_mask = conf_scores[cl].gt(self.conf_thresh)       # gt : greater than  でconf_threshよりおおきいconfは１、小さいconfは０になる\n",
    "                    # conf_scores : torch.Size([num_classes=21, 8732])\n",
    "                    # c_mask : torch.Size([8732])\n",
    "                    \n",
    "                    # scoresはtorch.Size([閾値を越えたBBox数])\n",
    "                    scores = conf_scores[cl][c_mask]\n",
    "                    \n",
    "                    # 閾値を超えたconfがない場合、つまりscores= []のときは何もしない\n",
    "                    if scores.nelement() == 0:\n",
    "                        continue\n",
    "                    \n",
    "                    # c_maskをdecoded_boxesに適応できるようにサイズを変更する\n",
    "                    l_mask = c_mask.unsqeeze(1).expand_as(decoded_boxes)   # 次元を増やしてdecoded_boxesの形に拡張する\n",
    "                    # l_mask : torch.Size([8732, 4])\n",
    "                    \n",
    "                    # l_maskをdecoded_boxesに適応\n",
    "                    boxes = decoded_boxes[l_mask].view(-1, 4)\n",
    "                    # よくわかんないけどdecoded_boxes[l_mask]で１次元になってしまうのでviewで[閾値を超えたBBox数, 4]に変形し直す\n",
    "                    \n",
    "                    # 3. Non-Maximum Suppressionを実施し、被っているBBoxを取り除く\n",
    "                    ids, count = nm_suppression(boxes, scores, self.nms_thresh, self.top_k)\n",
    "                    # ids : confの降順にNon-Maximum Suppressionを通過したindexが格納されている\n",
    "                    # count : Non-Maximum Suppressionを通過したBBoxの数\n",
    "                    \n",
    "                    # outputにNon-Maximum Suppressionを抜けた結果を格納\n",
    "                    # output : torch.SIze([num_batch, num_classes, self.top_k, 5])\n",
    "                    output[i, cl, :count] = torch.cat((scores[ids[:count]].unsquueeze(1), boxes[ids[:count]], 1))  # 横にconcat\n",
    "                    \n",
    "        return output  # torch.size([1, 21, 200, 5])   なんで１なんだ？\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n",
      "120\n",
      "torch.Size([1, 2, 3, 4, 5])\n",
      "16\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "# nelementの確認  （torch.numelのエイリアス）\n",
    "a = torch.randn(1,2,3,4,5)\n",
    "print(a.nelement())\n",
    "print(a.numel())\n",
    "print(a.shape)\n",
    "\n",
    "b = torch.zeros(4,4)\n",
    "print(b.nelement())\n",
    "print(b.numel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SSDモデルの実装 2回目\n",
    "ここまで実装したものをまとめて、forwardまで作る"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ssdクラスを作成\n",
    "\n",
    "class SSD(nn.Module):\n",
    "    \n",
    "    def __init__(self, phase, cfg):\n",
    "        super(self).__init__()   # ここわざとSSD(クラス名)入れないでやってみる\n",
    "        \n",
    "        self.phase = phase   # 'train' or 'inference'\n",
    "        self.num_classes = cfg['num_classes']  # クラス数=21\n",
    "        \n",
    "        # SSDのネットワークを作る\n",
    "        self.vgg = make_vgg()\n",
    "        self.extras = make_extras()\n",
    "        self.L2Norm = L2Norm()\n",
    "        self.loc, self.conf = make_loc_conf(cfg['num_classes'], cfg['bbox_aspect_num'])\n",
    "        \n",
    "        # DBox作成\n",
    "        dbox = DBox(cfg)\n",
    "        self.dbox_list = dbox.make_dbox_list()\n",
    "        \n",
    "        # inferenceのときはクラスDetectを用意する\n",
    "        if phase == 'inference':\n",
    "            self.detect = Detect()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        sources = list()   # locとconfへの入力　source1-6を格納\n",
    "        loc = list()\n",
    "        conf = list()\n",
    "        \n",
    "        # vggのconv4_3まで計算  make_vggで作ったモデルの(23)の出力\n",
    "        for k in range(23):\n",
    "            x = self.vgg[k](x)\n",
    "            \n",
    "        # conv4_3の　出力をL２Normに入力しsorce1を作成、sourcesに追加\n",
    "        source1 = self.L2Norm(x)\n",
    "        sources.append(source1)\n",
    "        \n",
    "        # vggを最後まで計算しsource2を作成、sourcesに追加\n",
    "        for k in range(23, len(self.vgg)):\n",
    "            x = self.vgg[k](x)\n",
    "   \n",
    "        sources.append(x)\n",
    "        \n",
    "        # extrasのconvとReLUを計算\n",
    "        # source3-6をsourcesに追加\n",
    "        for k, v in enumerate(self.extras):\n",
    "            # 1conv毎にreluを挟む\n",
    "            x = F.relu(v(x), inplace=True)\n",
    "            # 2conv毎にsourceとして抽出してsourcesに追加\n",
    "            if k%2 == 1:\n",
    "                sources.append(x)\n",
    "                \n",
    "        # source1-6にそれぞれ対応する畳込みを１回ずつ適用する\n",
    "        # zipでforループ回して、複数のリストの要素を一つずつ取得\n",
    "        # source1-6まであるので６回ループが回る\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " (extras): ModuleList(\n",
    "    (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
    "    (1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
    "    (2): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
    "    (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
    "    (4): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
    "    (5): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
    "    (6): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
    "    (7): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
