{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 形態素解析の実装\n",
    "1. クリーニング\n",
    "2. 正規化\n",
    "3. 形態素解析\n",
    "4. 基本形への変換\n",
    "5. stop wordの除去\n",
    "6. 単語の数値化\n",
    "\n",
    "aws上で<br>\n",
    "source activate pytorch_p36<br>\n",
    "pip install janome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from janome.tokenizer import Tokenizer\n",
    "j_t = Tokenizer()\n",
    "text = '機械学習が好きです'\n",
    "# 英語を入れるとどうなるのか\n",
    "text2 = 'splatoon2とスマブラとPocket Monstersとぷよぷよが好きです'\n",
    "# 古文だとどうなるか\n",
    "text3 ='今は昔、竹取の翁といふものありけり。野山にまじりて竹を取りつつ、よろづのことに使ひけり。' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "機械\t名詞,一般,*,*,*,*,機械,キカイ,キカイ\n",
      "学習\t名詞,サ変接続,*,*,*,*,学習,ガクシュウ,ガクシュー\n",
      "が\t助詞,格助詞,一般,*,*,*,が,ガ,ガ\n",
      "好き\t名詞,形容動詞語幹,*,*,*,*,好き,スキ,スキ\n",
      "です\t助動詞,*,*,*,特殊・デス,基本形,です,デス,デス\n"
     ]
    }
   ],
   "source": [
    "for token in j_t.tokenize(text):\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splatoon\t名詞,一般,*,*,*,*,splatoon,*,*\n",
      "2\t名詞,数,*,*,*,*,2,*,*\n",
      "と\t助詞,並立助詞,*,*,*,*,と,ト,ト\n",
      "スマ\t名詞,固有名詞,一般,*,*,*,スマ,スマ,スマ\n",
      "ブラ\t名詞,一般,*,*,*,*,ブラ,ブラ,ブラ\n",
      "と\t助詞,並立助詞,*,*,*,*,と,ト,ト\n",
      "Pocket\t名詞,固有名詞,組織,*,*,*,Pocket,*,*\n",
      " \t記号,空白,*,*,*,*, ,*,*\n",
      "Monsters\t名詞,固有名詞,組織,*,*,*,Monsters,*,*\n",
      "と\t助詞,並立助詞,*,*,*,*,と,ト,ト\n",
      "ぷよぷよが\t名詞,一般,*,*,*,*,ぷよぷよが,*,*\n",
      "好き\t名詞,形容動詞語幹,*,*,*,*,好き,スキ,スキ\n",
      "です\t助動詞,*,*,*,特殊・デス,基本形,です,デス,デス\n"
     ]
    }
   ],
   "source": [
    "for token in j_t.tokenize(text2):\n",
    "    print(token)\n",
    "    \n",
    "# splatoonと2に分かれる\n",
    "# スマとブラに分かれる\n",
    "# ぷよぷよが　が一つの名詞となる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "今\t名詞,副詞可能,*,*,*,*,今,イマ,イマ\n",
      "は\t助詞,係助詞,*,*,*,*,は,ハ,ワ\n",
      "昔\t名詞,副詞可能,*,*,*,*,昔,ムカシ,ムカシ\n",
      "、\t記号,読点,*,*,*,*,、,、,、\n",
      "竹\t名詞,一般,*,*,*,*,竹,タケ,タケ\n",
      "取\t動詞,自立,*,*,五段・ラ行,体言接続特殊２,取る,ト,ト\n",
      "の\t助詞,連体化,*,*,*,*,の,ノ,ノ\n",
      "翁\t名詞,固有名詞,人名,姓,*,*,翁,オウ,オウ\n",
      "といふ\t助詞,格助詞,連語,*,*,*,といふ,トイフ,トユウ\n",
      "もの\t名詞,非自立,一般,*,*,*,もの,モノ,モノ\n",
      "あり\t助動詞,*,*,*,五段・ラ行アル,連用形,ある,アリ,アリ\n",
      "けり\t助動詞,*,*,*,文語・ケリ,基本形,けり,ケリ,ケリ\n",
      "。\t記号,句点,*,*,*,*,。,。,。\n",
      "野山\t名詞,一般,*,*,*,*,野山,ノヤマ,ノヤマ\n",
      "に\t助詞,格助詞,一般,*,*,*,に,ニ,ニ\n",
      "まじり\t動詞,自立,*,*,五段・ラ行,連用形,まじる,マジリ,マジリ\n",
      "て\t助詞,接続助詞,*,*,*,*,て,テ,テ\n",
      "竹\t名詞,一般,*,*,*,*,竹,タケ,タケ\n",
      "を\t助詞,格助詞,一般,*,*,*,を,ヲ,ヲ\n",
      "取り\t動詞,自立,*,*,五段・ラ行,連用形,取る,トリ,トリ\n",
      "つつ\t助詞,接続助詞,*,*,*,*,つつ,ツツ,ツツ\n",
      "、\t記号,読点,*,*,*,*,、,、,、\n",
      "よろ\t動詞,自立,*,*,五段・ラ行,未然ウ接続,よる,ヨロ,ヨロ\n",
      "づのことに\t名詞,一般,*,*,*,*,づのことに,*,*\n",
      "使\t名詞,接尾,一般,*,*,*,使,シ,シ\n",
      "ひ\t動詞,自立,*,*,一段,連用形,ひる,ヒ,ヒ\n",
      "けり\t助動詞,*,*,*,文語・ケリ,基本形,けり,ケリ,ケリ\n",
      "。\t記号,句点,*,*,*,*,。,。,。\n"
     ]
    }
   ],
   "source": [
    "for token in j_t.tokenize(text3):\n",
    "    print(token)\n",
    "\n",
    "# よとづのことにがばらばらになる\n",
    "# けり　の　文語とは？　→　文章だけに用いる言語"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tokenizer_janomeの実装\n",
    "janomeの処理を機械学習実装時に使用しやすいように関数化したもの<br>\n",
    "単語の瀕死が必要ない場合は j_t.tokenizeの引数に wakati=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['機械', '学習', 'が', '好き', 'です']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenizer_janome(text):\n",
    "    return [tok for tok in j_t.tokenize(text, wakati=True)]\n",
    "\n",
    "text = '機械学習が好きです'\n",
    "tokenizer_janome(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<janome.tokenizer.Token at 0x7f759ebe6208>,\n",
       " <janome.tokenizer.Token at 0x7f759ebe6438>,\n",
       " <janome.tokenizer.Token at 0x7f759ebe64a8>,\n",
       " <janome.tokenizer.Token at 0x7f759ebe6518>,\n",
       " <janome.tokenizer.Token at 0x7f759ebe6588>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wakati=Falseだと\n",
    "def tokenizer_janome(text):\n",
    "    return [tok for tok in j_t.tokenize(text, wakati=False)]\n",
    "\n",
    "text = '機械学習が好きです'\n",
    "tokenizer_janome(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "機械\tキカイ\t機械\t名詞-一般\t\t\n",
      "学習\tガクシュウ\t学習\t名詞-サ変接続\t\t\n",
      "が\tガ\tが\t助詞-格助詞-一般\t\t\n",
      "好き\tスキ\t好き\t名詞-形容動詞語幹\t\t\n",
      "です\tデス\tです\t助動詞\t特殊・デス\t基本形\n",
      "EOS\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 追加辞書を使わない場合\n",
    "import MeCab\n",
    "m_t = MeCab.Tagger('-Ochasen')\n",
    "text = '機械学習が好きです'\n",
    "print(m_t.parse(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "機械学習\tキカイガクシュウ\t機械学習\t名詞-固有名詞-一般\t\t\n",
      "が\tガ\tが\t助詞-格助詞-一般\t\t\n",
      "好き\tスキ\t好き\t名詞-形容動詞語幹\t\t\n",
      "です\tデス\tです\t助動詞\t特殊・デス\t基本形\n",
      "EOS\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 追加辞書　neologdを使った場合\n",
    "m_t = MeCab.Tagger('-Ochasen -d /usr/lib/x86_64-linux-gnu/mecab/dic/mecab-ipadic-neologd')\n",
    "text = '機械学習が好きです'\n",
    "print(m_t.parse(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splatoon2\tスプラトゥーンツー\tSplatoon2\t名詞-固有名詞-一般\t\t\n",
      "と\tト\tと\t助詞-並立助詞\t\t\n",
      "スマブラ\tスマブラ\tスマブラ\t名詞-固有名詞-一般\t\t\n",
      "と\tト\tと\t助詞-並立助詞\t\t\n",
      "Pocket\tポケット\tPocket\t名詞-固有名詞-一般\t\t\n",
      "Monsters\tモンスターズ\tMONSTERS\t名詞-固有名詞-人名-一般\t\t\n",
      "と\tト\tと\t助詞-並立助詞\t\t\n",
      "ぷよぷよ\tプヨプヨ\tぷよぷよ\t名詞-固有名詞-一般\t\t\n",
      "が\tガ\tが\t助詞-格助詞-一般\t\t\n",
      "好き\tスキ\t好き\t名詞-形容動詞語幹\t\t\n",
      "です\tデス\tです\t助動詞\t特殊・デス\t基本形\n",
      "EOS\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(m_t.parse(text2))\n",
    "# splatoon2とスマブラが一つの単語として認識された！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# torchtextを用いたDataset, DataLoaderの実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 前処理と単語分割の関数を実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 単語分割にはJanomeを使用\n",
    "from janome.tokenizer import Tokenizer\n",
    "j_t = Tokenizer()\n",
    "\n",
    "def tokenizer_janome(text):\n",
    "    return [tok for tok in j_t.tokenize(text, wakati=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 前処理として正規化する関数\n",
    "import re\n",
    "\n",
    "def preprocessing_text(text):\n",
    "    # 改行、半角スペース、全角スペースを削除\n",
    "    text = re.sub('\\r', '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub(' ', '', text)\n",
    "    text = re.sub('　', '', text)\n",
    "    \n",
    "    # 数字文字の一律「０」化\n",
    "    text = re.sub(r'[0-9 ０-９]', '0', text)  # rは''の外\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['昨日', 'は', 'とても', '暑く', '、', '気温', 'が', '00', '度', 'も', 'あっ', 'た', '。']\n"
     ]
    }
   ],
   "source": [
    "#  前処理と単語分割を合わせた関数を定義する(上の２つの関数)\n",
    "\n",
    "def tokenizer_with_preprocessing(text):\n",
    "        text = preprocessing_text(text)  # 正規化\n",
    "        ret = tokenizer_janome(text)       # 単語分割 \n",
    "        \n",
    "        return ret\n",
    "    \n",
    "# 動作確認\n",
    "text = '昨日はとても暑く、気温が36度もあった。'\n",
    "print(tokenizer_with_preprocessing(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 文章データの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "\n",
    "# tsv, csvを読み込んだときに行う処理を定義\n",
    "# 文章とラベルの療法に用意する\n",
    "\n",
    "max_length = 25\n",
    "TEXT = torchtext.data.Field(sequential=True, tokenize=tokenizer_with_preprocessing, \n",
    "                           use_vocab=True, lower=True, include_lengths=True, batch_first=True, fix_length=max_length)\n",
    "LABEL = torchtext.data.Field(sequential=False, use_vocab=False)\n",
    "\n",
    "# 引数の意味は次の通り\n",
    "# sequential: データの長さが可変か？文章は長さがいろいろなのでTrue.ラベルはFalse\n",
    "# tokenize: 文章を読み込んだときに、前処理や単語分割をするための関数を定義\n",
    "# use_vocab：単語をボキャブラリー（単語集：後で解説）に追加するかどうか\n",
    "# lower：アルファベットがあったときに小文字に変換するかどうか\n",
    "# include_length: 文章の単語数のデータを保持するか\n",
    "# batch_first：ミニバッチの次元を先頭に用意するかどうか\n",
    "# fix_length：全部の文章を指定した長さと同じになるように、paddingまたは切り捨てします"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練データの数 4\n",
      "１つ目の訓練データ {'Text': ['王', 'と', '王子', 'と', '女王', 'と', '姫', 'と', '男性', 'と', '女性', 'が', 'い', 'まし', 'た', '。'], 'Label': '0'}\n",
      "2つ目の訓練データ {'Text': ['機械', '学習', 'が', '好き', 'です', '。'], 'Label': '1'}\n"
     ]
    }
   ],
   "source": [
    "# data.TabularDataset  Datasetに変換するクラス\n",
    "# フォルダ「data」から各tsvファイルを読み込みDatastにする\n",
    "# 1行がTEXTとLABELで区切られていることをfieldsで指示する\n",
    "\n",
    "train_ds, val_ds, test_ds = torchtext.data.TabularDataset.splits(\n",
    "    path='./data/', train='text_train.tsv', \n",
    "    validation='text_val.tsv', test='text_test.tsv', format='tsv',\n",
    "    fields=[('Text', TEXT), ('Label', LABEL)])\n",
    "# FieldとそのFieldに対する処理（上で定義したもの）\n",
    "\n",
    "# 動作確認\n",
    "print('訓練データの数', len(train_ds))\n",
    "print('１つ目の訓練データ', vars(train_ds[0]))\n",
    "print('2つ目の訓練データ', vars(train_ds[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 単語の数値化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'王': 1,\n",
       "         'と': 5,\n",
       "         '王子': 1,\n",
       "         '女王': 1,\n",
       "         '姫': 1,\n",
       "         '男性': 1,\n",
       "         '女性': 1,\n",
       "         'が': 3,\n",
       "         'い': 1,\n",
       "         'まし': 1,\n",
       "         'た': 1,\n",
       "         '。': 4,\n",
       "         '機械': 1,\n",
       "         '学習': 1,\n",
       "         '好き': 1,\n",
       "         'です': 1,\n",
       "         '本章': 2,\n",
       "         'から': 1,\n",
       "         '自然': 1,\n",
       "         '言語': 1,\n",
       "         '処理': 1,\n",
       "         'に': 1,\n",
       "         '取り組み': 1,\n",
       "         'ます': 2,\n",
       "         'で': 1,\n",
       "         'は': 1,\n",
       "         '商品': 1,\n",
       "         'レビュー': 1,\n",
       "         'の': 4,\n",
       "         '短い': 1,\n",
       "         '文章': 4,\n",
       "         'に対して': 1,\n",
       "         '、': 3,\n",
       "         'その': 1,\n",
       "         'ネガティブ': 1,\n",
       "         'な': 4,\n",
       "         '評価': 2,\n",
       "         'を': 3,\n",
       "         'し': 3,\n",
       "         'て': 2,\n",
       "         'いる': 2,\n",
       "         'か': 2,\n",
       "         'ポジティブ': 1,\n",
       "         '0': 1,\n",
       "         '値': 1,\n",
       "         'クラス': 1,\n",
       "         '分類': 2,\n",
       "         'する': 1,\n",
       "         'モデル': 1,\n",
       "         '構築': 1})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ボキャブラリーの作成\n",
    "# 訓練データの単語からmin_freq以上の頻度の単語を使用してボキャブラリーを構築\n",
    "TEXT.build_vocab(train_ds, min_freq=1)\n",
    "\n",
    "# 訓練データ内の単語と頻度を出力\n",
    "TEXT.vocab.freqs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<bound method Vocab._default_unk_index of <torchtext.vocab.Vocab object at 0x7f759eb77c88>>,\n",
       "            {'<unk>': 0,\n",
       "             '<pad>': 1,\n",
       "             'と': 2,\n",
       "             '。': 3,\n",
       "             'な': 4,\n",
       "             'の': 5,\n",
       "             '文章': 6,\n",
       "             '、': 7,\n",
       "             'が': 8,\n",
       "             'し': 9,\n",
       "             'を': 10,\n",
       "             'いる': 11,\n",
       "             'か': 12,\n",
       "             'て': 13,\n",
       "             'ます': 14,\n",
       "             '分類': 15,\n",
       "             '本章': 16,\n",
       "             '評価': 17,\n",
       "             '0': 18,\n",
       "             'い': 19,\n",
       "             'から': 20,\n",
       "             'する': 21,\n",
       "             'その': 22,\n",
       "             'た': 23,\n",
       "             'で': 24,\n",
       "             'です': 25,\n",
       "             'に': 26,\n",
       "             'に対して': 27,\n",
       "             'は': 28,\n",
       "             'まし': 29,\n",
       "             'クラス': 30,\n",
       "             'ネガティブ': 31,\n",
       "             'ポジティブ': 32,\n",
       "             'モデル': 33,\n",
       "             'レビュー': 34,\n",
       "             '値': 35,\n",
       "             '処理': 36,\n",
       "             '取り組み': 37,\n",
       "             '商品': 38,\n",
       "             '女性': 39,\n",
       "             '女王': 40,\n",
       "             '好き': 41,\n",
       "             '姫': 42,\n",
       "             '学習': 43,\n",
       "             '構築': 44,\n",
       "             '機械': 45,\n",
       "             '王': 46,\n",
       "             '王子': 47,\n",
       "             '男性': 48,\n",
       "             '短い': 49,\n",
       "             '自然': 50,\n",
       "             '言語': 51})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ボキャブラリーの単語をidに変換した結果を出力\n",
    "# min_freqより小さい場合は<unk>になる\n",
    "TEXT.vocab.stoi  # string to identifiers 文字列をidへ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoaderの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[46,  2, 47,  2, 40,  2, 42,  2, 48,  2, 39,  8, 19, 29, 23,  3,  1,  1,\n",
      "          1,  1,  1,  1,  1,  1,  1],\n",
      "        [45, 43,  8, 41, 25,  3,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "          1,  1,  1,  1,  1,  1,  1]]), tensor([16,  6]))\n",
      "tensor([0, 1])\n"
     ]
    }
   ],
   "source": [
    "# torchtextの文脈では単純にiteraterと呼ばれている\n",
    "train_dl = torchtext.data.Iterator(train_ds, batch_size=2, train=True)\n",
    "val_dl = torchtext.data.Iterator(val_ds, batch_size=2, train=False, sort=False)\n",
    "test_dl = torchtext.data.Iterator(test_ds, batch_size=2, train=False, sort=False)\n",
    "\n",
    "# 動作確認　検証データセットで確認\n",
    "# 一番目の用を取り出す\n",
    "batch = next(iter(val_dl))\n",
    "# textをidで表す\n",
    "print(batch.Text)\n",
    "print(batch.Label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
