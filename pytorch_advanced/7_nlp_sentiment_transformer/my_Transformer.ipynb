{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformerモデル（分類タスク用）の実装\n",
    "クラス分類のTransformerモデルの実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 目標\n",
    "1.\tTransformerのモジュール構成を理解する\n",
    "2.\tLSTMやRNNを使用せずCNNベースのTransformerで自然言語処理が可能な理由を理解する\n",
    "3.\tTransformerを実装できるようになる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup seeds\n",
    "torch.manual_seed(1234)\n",
    "np.random.seed(1234)\n",
    "random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedder(nn.Module):\n",
    "    \"\"\"\n",
    "    idで示されている単語をベクトルに変換する\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, text_embedding_vectors):\n",
    "        super(Embedder, self).__init__()\n",
    "        \n",
    "        self.embeddings = nn.Embedding.from_pretrained(\n",
    "            embeddings=text_embedding_vectors, freeze=True)\n",
    "        # freeze=Trueによりバックプロパゲーションで更新されず変化しなくなる\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x_vec = self.embeddings(x)\n",
    "            \n",
    "        return x_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "入力のテンソルサイズ： torch.Size([24, 256])\n",
      "出力のテンソルサイズ: torch.Size([24, 256, 300])\n"
     ]
    }
   ],
   "source": [
    "# 動作確認\n",
    "from utils.dataloader import get_IMDb_DataLoaders_and_TEXT\n",
    "train_dl, val_dl, test_dl, TEXT = get_IMDb_DataLoaders_and_TEXT(\n",
    "    max_length=256, batch_size=24)\n",
    "\n",
    "# ミニバッチ\n",
    "batch = next(iter(train_ld))\n",
    "\n",
    "# モデル構築\n",
    "net1 = Embedder(TEXT.vocab.vectors)\n",
    "\n",
    "# 入出力\n",
    "# idで表現されているデータを一つ取ってきてEmbedderに入れてちゃんとベクトル形式で表現されるか確認する\n",
    "x = batch.Text[0]\n",
    "x1 = net1(x)\n",
    "\n",
    "print('入力のテンソルサイズ：', x.shape)\n",
    "print('出力のテンソルサイズ:', x1.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Label',\n",
       " 'Text',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_get_field_values',\n",
       " 'batch_size',\n",
       " 'dataset',\n",
       " 'fields',\n",
       " 'fromvars',\n",
       " 'input_fields',\n",
       " 'target_fields']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batch.Text)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batch.Label)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   2,   14,   55,  ...,    1,    1,    1],\n",
      "        [   2,  396,    6,  ...,    1,    1,    1],\n",
      "        [   2,   38, 9369,  ...,   66,   48,    3],\n",
      "        ...,\n",
      "        [   2,   58,   14,  ...,    5,  940,    3],\n",
      "        [   2,  552,    6,  ...,    1,    1,    1],\n",
      "        [   2, 1595, 9274,  ...,    7,    0,    3]])\n",
      "torch.Size([24, 256])\n"
     ]
    }
   ],
   "source": [
    "print(batch.Text[0])             # 各文章をidで示したもの\n",
    "print(batch.Text[0].size())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([163, 154, 256, 154, 195, 256, 256, 256,  66,  94, 256, 256, 159, 177,\n",
      "        182,  94, 256, 170, 146, 256,  81, 256, 178, 256])\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "print(batch.Text[1])          # 各文章の単語数\n",
    "print(len(batch.Text[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.Label   # ネガポジのラベル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    入力された単語の位置を表すベクトル情報を付加する\n",
    "    cosとsinを使う\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model=300, max_seq_len=256):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model  # 単語ベクトルの次元数\n",
    "        \n",
    "        # 単語の順番(pos)と埋め込みベクトルの次元の位置(i)によって一意に定まる値の表をpeとして作成\n",
    "        pe = torch.zeros(max_seq_len, d_model)\n",
    "        \n",
    "        # GPUが使える場合はGPUへ送る、ここでは省略。実際に学習時には使用する\n",
    "        # device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        # pe = pe.to(device)\n",
    "        \n",
    "        for pos in range(max_seq_len):\n",
    "            for i in range(0, d_model, 2):\n",
    "                pe[pos, i] = math.sin(pos / (10000**((2*i)/d_model)))\n",
    "                pe[pos, i+1] = math.cos(pos / (10000**((2*i)/d_model)))\n",
    "                \n",
    "        # 表peの先頭にミニバッチ次元となる次元を足す\n",
    "        self.pe = pe.unsqueeze(0)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # 入力とpositional encodingを足し算する  掛け算ではない\n",
    "        # x　がpeよりも小さいので大きくする\n",
    "        ret = math.sqrt(self.d_model)*x + self.pe  # ブロードキャストされる？\n",
    "        return ret\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "入力のテンソルサイズ： torch.Size([24, 256, 300])\n",
      "出力のテンソルサイズ: torch.Size([24, 256, 300])\n"
     ]
    }
   ],
   "source": [
    "# 動作確認\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# モデル構築\n",
    "net1 = Embedder(TEXT.vocab.vectors)\n",
    "net2 = PositionalEncoder(d_model=300, max_seq_len=256)\n",
    "# net1.to(device)\n",
    "# net2.to(device)\n",
    "\n",
    "# 入出力\n",
    "x = batch.Text[0]\n",
    "x1 = net1(x)\n",
    "x2 = net2(x1)\n",
    "\n",
    "print('入力のテンソルサイズ：', x1.shape)\n",
    "print('出力のテンソルサイズ:', x2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    \"\"\"\n",
    "    TransformerはマルチヘッドAttention\n",
    "    今回はシングルAttentionで実装\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, d_model=300):\n",
    "        super().__init__()\n",
    "        \n",
    "        # SAGANではpointwiseだったが、Transformerでは全結合で特徴量を変換する\n",
    "        self.q_linear = nn.Linear(d_model, d_model)\n",
    "        self.v_linear = nn.Linear(d_model, d_model)\n",
    "        self.k_linear = nn.Linear(d_model, d_model)\n",
    "        \n",
    "        # 出力時に使用する全結合層\n",
    "        self.out = nn.Linear(d_model, d_model)\n",
    "        \n",
    "        # Attentionの大きさ調節の変数\n",
    "        self.d_k = d_model\n",
    "        \n",
    "    def forward(self, q, k, v, mask):\n",
    "        # 全結合層で特徴量を変換\n",
    "        k = self.k_linear(k)\n",
    "        q = self.q_linear(q)\n",
    "        v = self.v_linear(v)\n",
    "        \n",
    "        # Attentionの値を計算\n",
    "        # 各値を足し算すると大きくなりすぎるのでroot(d_k)でわって調整\n",
    "        weights = torch.matmul(q, k.transpose(1,2) / math.sqrt(self.d_k))\n",
    "        \n",
    "        # ここでmaskを計算\n",
    "        mask = mask.unsqueeze(1)\n",
    "        weights = weights.masked_fill(mask==0, -1e9)\n",
    "        \n",
    "        # softmaxで規格化\n",
    "        # 各単語一つずつ正規化していく\n",
    "        normlized_weights = F.softmax(weights, dim=-1)\n",
    "        \n",
    "        # AttentionをValueと掛け算\n",
    "        output = torch.matmul(normlized_weights, v)\n",
    "        \n",
    "        # 全結合層で特徴量を変換\n",
    "        output = self.out(output)\n",
    "    \n",
    "        return output, normlized_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff=1024, dropout=0.1):\n",
    "        \"\"\"\n",
    "        Attention層から出力を単純に全結合層２つで特徴量を変換するユニット\n",
    "        重みを増やして表現力を大きくするためと捉えておけばいい？\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.linear_1 = nn.Linear(d_model, d_ff)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear_2 = nn.Linear(d_ff, d_model)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.linear_1(x)\n",
    "        x = self.dropout(F.relu(x))\n",
    "        x = self.linear_2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        # layernormalization層\n",
    "        self.norm_1 = nn.LayerNorm(d_model)\n",
    "        self.norm_2 = nn.LayerNorm(d_model)\n",
    "        \n",
    "        # Attention層\n",
    "        self.attn = Attention(d_model)\n",
    "        \n",
    "        # Attention層の後の全結合層２つ\n",
    "        self.ff = FeedForward(d_model)\n",
    "        \n",
    "        # Dropout\n",
    "        self.dropout_1 = nn.Dropout(dropout)\n",
    "        self.dropout_2 = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        # 正規化とAttention\n",
    "        x_normlized = self.norm_1(x)\n",
    "        output, normlized_weights = self.attn(x_normlized, x_normlized, x_normlized, mask)\n",
    "        \n",
    "        x2 = x+self.dropout_1(output)\n",
    "        \n",
    "        # 正規化と全結合層\n",
    "        x_normlized2 = self.norm_2(x2)\n",
    "        output = x + self.dropout_2(self.ff(x_normlized2))\n",
    "        \n",
    "        return output, normlized_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(True)\n",
      "入力のテンソルサイズ： torch.Size([24, 256, 300])\n",
      "出力のテンソルサイズ: torch.Size([24, 256, 300])\n",
      "Attentionのサイズ: torch.Size([24, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "# 動作確認\n",
    "\n",
    "# モデル構築\n",
    "net1 = Embedder(TEXT.vocab.vectors)\n",
    "net2 = PositionalEncoder(d_model=300, max_seq_len=256)\n",
    "net3 = TransformerBlock(d_model=300)\n",
    "\n",
    "# mask作成\n",
    "x = batch.Text[0][1]\n",
    "input_pad = 1  # <pad>のidは１\n",
    "input_mask = (x!=input_pad)\n",
    "print(input_mask[0])\n",
    "\n",
    "# 入出力\n",
    "x = batch.Text[0]\n",
    "x1 = net1(x)     # 単語をベクトルにする\n",
    "x2 = net2(x1)  # Position情報を加算\n",
    "x3, normlized_weights = net3(x2, input_mask)   # self-attentinoで特徴量を変換\n",
    "\n",
    "print('入力のテンソルサイズ：', x2.shape)\n",
    "print('出力のテンソルサイズ:', x3.shape)\n",
    "print('Attentionのサイズ:', normlized_weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([163, 154, 256, 154, 195, 256, 256, 256,  66,  94, 256, 256, 159, 177,\n",
       "        182,  94, 256, 170, 146, 256,  81, 256, 178, 256])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.Text[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationHead(nn.Module):\n",
    "    \"\"\"\n",
    "    Transformer_Blockの出力を使用し、最後にクラス分類する\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, d_model=300, output_dim=2):\n",
    "        super().__init__()\n",
    "        \n",
    "        # 全結合層\n",
    "        self.linear = nn.Linear(d_model, output_dim)  # neg, posi の２値分類\n",
    "        \n",
    "        # 重み初期化処理\n",
    "        nn.init.normal_(self.linear.weight, std=0.02)\n",
    "        nn.init.normal_(self.linear.bias, 0)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x0 = x[:, 0, :]  # 各バッチの各文の先頭の単語<cls>の特徴量(３００次元)を取り出す\n",
    "        # 最初は各バッチの各文の先頭の単語<cls>にネガポジに重要な特徴量が集まるわけではないが\n",
    "        # これを使って損失関数から学習させることでネガポジに重要な特徴量が集まるようになる\n",
    "        out = self.linear(x0)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "入力のテンソルサイズ： torch.Size([24, 256, 300])\n",
      "出力のテンソルサイズ： torch.Size([24, 2])\n"
     ]
    }
   ],
   "source": [
    "# 動作確認\n",
    "\n",
    "# ミニバッチの用意\n",
    "batch = next(iter(train_dl))\n",
    "\n",
    "# モデル構築\n",
    "net1 = Embedder(TEXT.vocab.vectors)\n",
    "net2 = PositionalEncoder(d_model=300, max_seq_len=256)\n",
    "net3 = TransformerBlock(d_model=300)\n",
    "net4 = ClassificationHead(output_dim=2, d_model=300)\n",
    "\n",
    "# 入出力\n",
    "x = batch.Text[0]\n",
    "x1 = net1(x)  # 単語をベクトルに\n",
    "x2 = net2(x1)  # Positon情報を足し算\n",
    "x3, normlized_weights = net3(x2, input_mask)  # Self-Attentionで特徴量を変換\n",
    "x4 = net4(x3)  # 最終出力の0単語目を使用して、分類0-1のスカラーを出力\n",
    "\n",
    "print(\"入力のテンソルサイズ：\", x3.shape)\n",
    "print(\"出力のテンソルサイズ：\", x4.shape)  # 2値になった！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最終的なTransformerモデル\n",
    "class TransformerClassification(nn.Module):\n",
    "    \"\"\"\n",
    "    Transformerでクラス分類させる\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, text_embedding_vectors, d_model=300, max_seq_len=256, output_dim=2):\n",
    "        super().__init__()\n",
    "        \n",
    "        # モデル構築\n",
    "        self.net1 = Embedder(text_embedding_vectors)\n",
    "        self.net2 = PositionalEncoder(d_model=d_model, max_seq_len=max_seq_len)\n",
    "        self.net3_1 = TransformerBlock(d_model=d_model)\n",
    "        self.net3_2 = TransformerBlock(d_model=d_model)\n",
    "        self.net4 = ClassificationHead(output_dim=output_dim, d_model=d_model)\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        x1 = self.net1(x)\n",
    "        x2 = self.net2(x1)\n",
    "        x3_1, normlized_weights_1 = self.net3_1(x2, mask)\n",
    "        x3_2, normlized_weights_2 = self.net3_2(x3_1, mask)\n",
    "        x4 = self.net4(x3_2)\n",
    "        return x4, normlized_weights_1, normlized_weights_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "出力のテンソルサイズ： torch.Size([24, 2])\n",
      "出力テンソルのsigmoid： tensor([[0.7040, 0.2960],\n",
      "        [0.7210, 0.2790],\n",
      "        [0.7165, 0.2835],\n",
      "        [0.7176, 0.2824],\n",
      "        [0.7153, 0.2847],\n",
      "        [0.6998, 0.3002],\n",
      "        [0.7044, 0.2956],\n",
      "        [0.6537, 0.3463],\n",
      "        [0.7234, 0.2766],\n",
      "        [0.7117, 0.2883],\n",
      "        [0.7344, 0.2656],\n",
      "        [0.7086, 0.2914],\n",
      "        [0.7084, 0.2916],\n",
      "        [0.6949, 0.3051],\n",
      "        [0.7348, 0.2652],\n",
      "        [0.7108, 0.2892],\n",
      "        [0.7294, 0.2706],\n",
      "        [0.7114, 0.2886],\n",
      "        [0.6899, 0.3101],\n",
      "        [0.7187, 0.2813],\n",
      "        [0.7341, 0.2659],\n",
      "        [0.7272, 0.2728],\n",
      "        [0.6806, 0.3194],\n",
      "        [0.7194, 0.2806]], grad_fn=<SoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "# 動作確認\n",
    "\n",
    "# ミニバッチの用意\n",
    "batch = next(iter(train_dl))\n",
    "\n",
    "# モデル構築\n",
    "net = TransformerClassification(\n",
    "    text_embedding_vectors=TEXT.vocab.vectors, d_model=300, max_seq_len=256, output_dim=2)\n",
    "\n",
    "# 入出力\n",
    "x = batch.Text[0]\n",
    "input_mask = (x != input_pad)\n",
    "out, normlized_weights_1, normlized_weights_2 = net(x, input_mask)\n",
    "\n",
    "print(\"出力のテンソルサイズ：\", out.shape)\n",
    "print(\"出力テンソルのsigmoid：\", F.softmax(out, dim=1))\n",
    "# これは何も学習していない状態でmodelにデータを流し込んだもの"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.8202, 0.9536],\n",
       "        [1.8337, 0.8841],\n",
       "        [1.8335, 0.9062],\n",
       "        [1.7762, 0.8435],\n",
       "        [1.7039, 0.7828],\n",
       "        [1.7933, 0.9470],\n",
       "        [1.8516, 0.9832],\n",
       "        [1.6864, 1.0509],\n",
       "        [1.8136, 0.8524],\n",
       "        [1.8807, 0.9773],\n",
       "        [1.9339, 0.9167],\n",
       "        [1.8253, 0.9366],\n",
       "        [1.7886, 0.9010],\n",
       "        [1.8111, 0.9879],\n",
       "        [1.8514, 0.8325],\n",
       "        [1.8015, 0.9021],\n",
       "        [1.8377, 0.8462],\n",
       "        [1.7442, 0.8418],\n",
       "        [1.6814, 0.8817],\n",
       "        [1.7247, 0.7865],\n",
       "        [1.8430, 0.8273],\n",
       "        [1.8306, 0.8499],\n",
       "        [1.7425, 0.9862],\n",
       "        [1.8266, 0.8851]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
