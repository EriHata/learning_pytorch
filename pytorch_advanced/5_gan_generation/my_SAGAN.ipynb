{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self Attention GANの実装\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# パッケージのimport\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "np.random.seed(123)\n",
    "random.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## self attentionとは\n",
    "DCGANのGeneratorではDeconvで拡大する際どうしても局所情報の拡大になってしまい、大域的な情報が含まれない<br>\n",
    "大域的な情報を含んだ拡大を実現するのがself attentionという技術"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1x1 Convolutions (pointwise convolution)とは\n",
    "出力チャネルが1だけ -> 入力xをチャネルごとに線形和をとったもの<br>\n",
    "出力チャネルが複数 -> 異なる係数で（重み）でチャネルごとに線形和をとったものを出力チャネル分だけ用意する<br>\n",
    "\n",
    "次元圧縮とも言える<br>\n",
    "情報が欠落しにくい線形和の係数を学習してくれる\n",
    "\n",
    "次元が圧縮され、計算量が少なくなることを活かして、エッジ端末で使われるmobile netでも使用される"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectral Normalizationとは\n",
    "ネットワークの重みの正規化<br>\n",
    "GANがうまく学習するにはDiscriminatorがリプシッツ連続星を保つ必要がある→<br>\n",
    "リプシッツ連続をDiscriminatorのネットワークが有するにはどうすればいいか→<br>\n",
    "Spectral Normalizationで重みを正規化する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## self attentionモジュールの実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Self_Attention(nn.Module):\n",
    "    \"\"\"\n",
    "    self attentionのlayer\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, in_dim):\n",
    "        \"\"\"\n",
    "        query:\n",
    "            元の入力xの転置に対応するもの\n",
    "        key:\n",
    "            元の入力xに対応するもの\n",
    "        value:\n",
    "            attention mapと掛け算する対象\n",
    "        \"\"\"\n",
    "        super(Self_Attention, self).__init__()\n",
    "        \n",
    "        # pointwise convolutionを用意\n",
    "        # pointwiseなのでkernel_size=1\n",
    "        self.query_conv = nn.Conv2d(\n",
    "            in_channels=in_dim, out_channels=in_dim//8, kernel_size=1)\n",
    "        self.key_conv = nn.Conv2d(\n",
    "            in_channels=in_dim, out_channels=in_dim//8, kernel_size=1)\n",
    "        self.value_conv = nn.Conv2d(\n",
    "            in_channels=in_dim, out_channels=in_dim, kernel_size=1)\n",
    "        \n",
    "        # attention map作成時の規格化のソフトマックス\n",
    "        self.softmax = nn.Softmax(dim=-2)\n",
    "        \n",
    "        # もとの入力ｘとself attention map(o)を加算するときの係数\n",
    "        # 最初はgammma=0で学習させていく\n",
    "        # nn.Parameter : pytocrhで学習可能な変数を作成する命令\n",
    "        # これはインスタンス変数で保持しておく必要があるのかな？\n",
    "        self.gamma = nn.Parameter(torch.zeros(1))  \n",
    "        \n",
    "    def forward(self, x):\n",
    "        # 入力変数  B, C, W, H\n",
    "        X = x\n",
    "        \n",
    "        # 畳み込み後にサイズを変更 B, C', W, H -> B, C', N\n",
    "        proj_query = self.query_conv(X).view(\n",
    "            X.shape[0], -1, X.shape[2]*X.shape[3])  # channelのサイズが変わるので-1\n",
    "        proj_query = proj_query.permute(0, 2, 1)  # 転置　　B, N, C'\n",
    "        proj_key = self.key_conv(X).view(\n",
    "            X.shape[0], -1, X.shape[2]*X.shape[3])  # channelのサイズが変わるので-1\n",
    "                                                                                   # B, C', N\n",
    "\n",
    "        # 掛け算\n",
    "        S = torch.bmm(proj_query, proj_key)  # bmm : バッチごとの掛け算\n",
    "        \n",
    "        # 規格化\n",
    "        attention_map_T = self.softmax(S)  # 行i方向の和を1にするsoftmax\n",
    "        attention_map = attention_map_T.permute(0, 2, 1)  # 転置\n",
    "        \n",
    "        # self attentino mapを計算\n",
    "        proj_value = self.value_conv(X).view(\n",
    "            X.shape[0], -1, X.shape[2]*X.shape[3])  # B, C, N\n",
    "        o = torch.bmm(proj_value, attention_map.permute(0, 2, 1))  # bmm : バッチごとの掛け算\n",
    "        # attention mapは転置して掛け算\n",
    "        \n",
    "        # self attentino mapであるoのテンソルサイズをXに揃えて出力にする\n",
    "        o = o.view(X.shape[0], X.shape[1], X.shape[2], X.shape[3])\n",
    "        out = x + self.gamma*o\n",
    "        \n",
    "        return out, attention_map  # attention_mapはattentionの強さを可視化するために使用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generatorの実装\n",
    "DCGANからの変更点\n",
    "- Deconv層にSpectral Normalizationを追加する\n",
    "- self attentionモジュールを追加する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim=20, image_size=64):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.layer1= nn.Sequential(\n",
    "            # Spectral Normalizationを追加\n",
    "            nn.utils.spectral_norm(\n",
    "                nn.ConvTranspose2d(z_dim, image_size*8, kernel_size=4, stride=1)),\n",
    "            nn.BatchNorm2d(image_size*8),\n",
    "            nn.ReLU(inplace=True))\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            # Spectral Normalizationを追加\n",
    "            nn.utils.spectral_norm(\n",
    "                nn.ConvTranspose2d(image_size*8, image_size*4, kernel_size=4, stride=2, padding=1)),\n",
    "            nn.BatchNorm2d(image_size*4),\n",
    "            nn.ReLU(inplace=True))\n",
    "        \n",
    "        self.layer3 = nn.Sequential(\n",
    "            # Spectral Normalizationを追加\n",
    "            nn.utils.spectral_norm(\n",
    "                nn.ConvTranspose2d(image_size*4, image_size*2, kernel_size=4, stride=2, padding=1)),\n",
    "            nn.BatchNorm2d(image_size*2),\n",
    "            nn.ReLU(inplace=True))\n",
    "        \n",
    "        # self attention層を追加\n",
    "        self.self_attention1 = Self_Attention(in_dim=image_size*2)\n",
    "        \n",
    "        self.layer4 = nn.Sequential(\n",
    "            # Spectral Normalizationを追加\n",
    "            nn.utils.spectral_norm(\n",
    "                nn.ConvTranspose2d(image_size*2, image_size, kernel_size=4, stride=2, padding=1)),\n",
    "            nn.BatchNorm2d(image_size),\n",
    "            nn.ReLU(inplace=True))\n",
    "        \n",
    "        # self attention層を追加\n",
    "        self.self_attention2 = Self_Attention(in_dim=image_size)\n",
    "        \n",
    "        self.last = nn.Sequential(\n",
    "            # Spectral Normalizationはしない\n",
    "            nn.ConvTranspose2d(image_size, 1, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Tanh())  # -1~1の出力になる\n",
    "        \n",
    "        \n",
    "    def forward(self, z):\n",
    "        out = self.layer1(z)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out, attention_map1 = self.self_attention1(out)\n",
    "        out = self.layer4(out)\n",
    "        out, attention_map2 = self.self_attention2(out)\n",
    "        out = self.last(out)\n",
    "        \n",
    "        return out, attention_map1, attention_map2  #  outと2つのattention_mapを返す\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 動作確認\n",
    "# どこかにミスがある前提で動作確認するほうがいい\n",
    "# 修正するための動作確認だから\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# 偽画像の生成\n",
    "G = Generator(z_dim=20, image_size=64)\n",
    "input_z = torch.randn(1, 20)\n",
    "input_z = input_z.view(input_z.size(0), input_z.size(1), 1, 1)\n",
    "fake_images, attention_map1, attention_map2 = G(input_z)\n",
    "\n",
    "# 偽画像の表示\n",
    "image_transformed = fake_images[0][0].detach().numpy()  # 64x64\n",
    "plt.imshow(image_transformed, 'gray')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator\n",
    "DCGANからの変更点(Generatorと一緒)\n",
    "- Deconv層にSpectral Normalizationを追加する\n",
    "- self attentionモジュールを追加する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, z_dim, image_size=64):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        # layerを用意しておく\n",
    "        self.layer1 = nn.Sequential(\n",
    "            # Spectral normalization\n",
    "            nn.utils.spectral_norm(nn.Conv2d(1, image_size, kernel_size=4, stride=2, padding=1)),\n",
    "            nn.LeakyReLU(0.1, inplace=True))\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            # Spectral normalization\n",
    "            nn.utils.spectral_norm(nn.Conv2d(image_size, image_size*2, kernel_size=4, stride=2, padding=1)),\n",
    "            nn.LeakyReLU(0.1, inplace=True))\n",
    "        \n",
    "        self.layer3 = nn.Sequential(\n",
    "            # Spectral normalization\n",
    "            nn.utils.spectral_norm(nn.Conv2d(image_size*2, image_size*4, kernel_size=4, stride=2, padding=1)),\n",
    "            nn.LeakyReLU(0.1, inplace=True))\n",
    "        \n",
    "        self.self_attention1 = Self_Attention(in_dim=image_size*4)\n",
    "        \n",
    "        self.layer4 = nn.Sequential(\n",
    "            # Spectral normalization\n",
    "            nn.utils.spectral_norm(nn.Conv2d(image_size*4, image_size*8, kernel_size=4, stride=2, padding=1)),\n",
    "            nn.LeakyReLU(0.1, inplace=True))\n",
    "        \n",
    "        self.self_attention2 = Self_Attention(in_dim=image_size*8)\n",
    "        \n",
    "        self.last = nn.Conv2d(image_size*8, 1, kernel_size=4, stride=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out, attention_map1 = self.self_attention1(out)\n",
    "        out = self.layer4(out)\n",
    "        out, attention_map2 = self.self_attention2(out)\n",
    "        out = self.last(out)\n",
    "        \n",
    "        return out, attention_map1, attention_map2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.5141]]]], grad_fn=<SigmoidBackward>)\n"
     ]
    }
   ],
   "source": [
    "# 動作確認\n",
    "D = Discriminator(z_dim=20, image_size=64)\n",
    "\n",
    "#　偽画像生成して判定\n",
    "input_z = torch.randn(1, 20)\n",
    "input_z = input_z.view(input_z.size(0), input_z.size(1), 1, 1)\n",
    "fake_images, _, _ = G(input_z)\n",
    "d_out, attention_map1, attention_map2 = D(fake_images)\n",
    "\n",
    "print(nn.Sigmoid()(d_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoaderの作成\n",
    "変更点はなし"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_datapath_list():\n",
    "    \"\"\"\n",
    "    学習の画像データへのファイルパスリストを作成\n",
    "    \"\"\"\n",
    "    \n",
    "    train_img_list = []\n",
    "    for img_idx in range(200):\n",
    "        img_path = './data/img_78/img_7_' + str(img_idx) + '.jpg'\n",
    "        train_img_list.append(img_path)\n",
    "        \n",
    "        img_path = './data/img_78/img_8_' + str(img_idx) + '.jpg'\n",
    "        train_img_list.append(img_path)\n",
    "        \n",
    "    return train_img_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageTransform():\n",
    "    \"\"\"画像の前処理クラス\"\"\"\n",
    "    \n",
    "    def __init__(self, mean, std):\n",
    "        self.data_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean, std)\n",
    "        ])\n",
    "        \n",
    "    def __call__(self, img):\n",
    "        return self.data_transform(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN_Img_Dataset(data.Dataset):\n",
    "    '''\n",
    "    画像のDatasetクラス\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, file_list, transform):\n",
    "        self.file_list = file_list\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        画像のTensor形式のデータを取得\n",
    "        \"\"\"\n",
    "        img_path = self.file_list[index]\n",
    "        img = Image.open(img_path)  # 高さ、幅、色【白黒】\n",
    "        \n",
    "        # 画像の前処理\n",
    "        img_transformed = self.transform(img)\n",
    "        \n",
    "        return img_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "# DataLoaderの作成と動作確認\n",
    "\n",
    "# ファイルリストの作成\n",
    "train_img_list = make_datapath_list()\n",
    "\n",
    "# Datasetを作成\n",
    "mean  = (0.5,)  # カンマがないとエラーになる\n",
    "std = (0.5,)\n",
    "train_dataset = GAN_Img_Dataset(file_list=train_img_list, transform=ImageTransform(mean, std))\n",
    "\n",
    "# DataLoaderの作成\n",
    "batch_size = 64\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# 動作の確認\n",
    "batch_iterator = iter(train_dataloader)  # イテレータに変換\n",
    "images = next(batch_iterator)\n",
    "print(images.size())  # torch.Size([])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習\n",
    "SAGANでは損失関数に hinge version of the adversarial lossを使う<br>\n",
    "logなし、平均を取る<br>\n",
    "Discriminatorの方でReLU使ってる<br>\n",
    "\n",
    "GANの損失関数は多数提案されているが、それらは経験的にうまくいくからと言う理由で使用されていることが多い"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルを学習させる関数を作成\n",
    "\n",
    "def train_model(G, D, dataloader, num_epochs):\n",
    "    # GPUが使えるかを確認\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"使用デバイス：\", device)\n",
    "    \n",
    "    # 最適化手法の設定\n",
    "    g_lr, d_lr = 0.0001, 0.0004\n",
    "    beta1, beta2 = 0.0, 0.9\n",
    "    g_optimizer = torch.optim.Adam(G.parameters(), g_lr, [beta1, beta2])\n",
    "    d_optimizer = torch.optim.Adam(D.parameters(), d_lr, [beta1, beta2])\n",
    "    \n",
    "    z_dim = 20\n",
    "    mini_batch_size = 64  # この一文はなんのためにあるの？\n",
    "    \n",
    "    # ハードに送って\n",
    "    G.to(device)\n",
    "    D.to(device)\n",
    "    \n",
    "    # 訓練モードに設定\n",
    "    G.train()\n",
    "    D.train()\n",
    "\n",
    "    torch.backends.cudnn.bencmark = True\n",
    "    \n",
    "    num_train_imgs = len(dataloader.dataset)\n",
    "    batch_size = dataloader.batch_size\n",
    "    \n",
    "    # イテレーションカウンタのセット\n",
    "    iteration = 1\n",
    "    logs = []\n",
    "    \n",
    "    # epochのループ\n",
    "    for epoch in range(num_epochs):\n",
    "        # 開始時刻\n",
    "        t_epoch_start = time.time()\n",
    "        epoch_loss_g = 0.0\n",
    "        epoch_loss_d = 0.0\n",
    "        \n",
    "        print('------------')\n",
    "        print('Epoch : {}/{}'.format(epoch, num_epochs))\n",
    "        print('------------')\n",
    "        print('(train)')\n",
    "        \n",
    "        # データローダからminibatcずつ取り出すループ\n",
    "        for images in dataloader:  # ここはiteratorにしなくても取り出してくれる\n",
    "            # --------------------\n",
    "            # 1. Discriminatorの学習\n",
    "            # --------------------\n",
    "            if images.size()[0] == 1:\n",
    "                continue\n",
    "            \n",
    "            images.to(device)\n",
    "            \n",
    "            # epochの最後のイテレーションはミニバッチサイズの数が少なくなる\n",
    "            mini_batch_size = images.size()[0]\n",
    "            \n",
    "            # 真の画像を判定\n",
    "            d_out_real, _, _ = D(images)\n",
    "            \n",
    "            # 偽の画像を生成して判定\n",
    "            input_z = torch.randn(mini_batch_size, z_dim).to(device)\n",
    "            input_z = input_z.view(input_z.size(0), input_z.size(1), 1, 1)\n",
    "            fake_images, _, _ = G(input_z)\n",
    "            d_out_fake, _, _ = D(fake_images)\n",
    "            # D, Gどちらもattention mapが生成される\n",
    "            # Dのattention mapってどんなもの？\n",
    "            \n",
    "            # 誤差計算　hinge version of the adversarial lossに変更\n",
    "            d_loss_real = torch.nn.ReLU()(1.0-d_out_real).mean()\n",
    "            # d_out_realが１以上の場合誤差0になる\n",
    "            \n",
    "            d_loss_fake = torch.nn.ReLU()(1.0+d_out_fake).mean()\n",
    "            # d_loss_fakeが−１以下なら誤差0になる\n",
    "            \n",
    "            d_loss = d_loss_real + d_loss_fake\n",
    "            \n",
    "            # backpropagation\n",
    "            g_optimizer.zero_grad()\n",
    "            d_optimizer.zero_grad()\n",
    "            \n",
    "            d_loss.backward()\n",
    "            d_optimizer.step()\n",
    "            \n",
    "            # --------------------\n",
    "            # 2. Generatorの学習\n",
    "            # --------------------\n",
    "            # 偽の画像を生成して判定\n",
    "            input_z = torch.randn(mini_batch_size, z_dim).to(device)\n",
    "            input_z = input_z.view(input_z.size(0), input_z.size(1), 1, 1)\n",
    "            fake_images, _, _ = G(input_z)\n",
    "            d_out_fake, _, _ = D(fake_images)\n",
    "            \n",
    "            # 誤差計算　hinge version of the adversarial lossに変更\n",
    "            g_loss = d_out_fake.mean()\n",
    "            \n",
    "            # backpropagation\n",
    "            g_optimizer.zero_grad()\n",
    "            d_optimizer.zero_grad()\n",
    "            \n",
    "            g_loss.backward()\n",
    "            g_optimizer.step()\n",
    "            \n",
    "            # --------------------\n",
    "            # 3. 記録\n",
    "            # --------------------\n",
    "            epoch_d_loss += d_loss.item()  # .item()忘れがち\n",
    "            epoch_g_loss += g_loss.item()\n",
    "            iteration += 1 \n",
    "            \n",
    "        # epochごとのlossと計算時間\n",
    "        t_epoch_finish = time.time()\n",
    "        print('------------')\n",
    "        # loss計算するときにすでにmean()取ってるので、iterationで割るほうが正しくない？\n",
    "        print('epoch {} || Epoch_D_Loss :{:.4f} || Epoch_G_Loss :{:.4f}'.format(\n",
    "            epoch, epoch_d_loss/iteration, epoch_g_loss/iteration))\n",
    "        print('timer : {:.4f} sec.'.format(t_epoch_finish - t_epoch_start))\n",
    "        t_epoch_start = time.time()\n",
    "        \n",
    "    return G, D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ネットワークの初期化\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__  # オブジェクトのクラス名を取得\n",
    "    if classname.find('Conv') != -1:  # 文字列中の任意の文字列の位置を取得　含まれていなければ-1\n",
    "        # Conv2dとConvTranspose2dの重みの初期化\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        # BatchNorm2dの重みの初期化\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "        \n",
    "# 重みの初期化の実施\n",
    "G.apply(weights_init)\n",
    "D.apply(weights_init)\n",
    "\n",
    "print('ネットワークの初期化完了')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習・検証の実施\n",
    "num_epochs = 300\n",
    "G_updata, D_update = train_model(\n",
    "    G, D, dataloader=train_dataloader, num_epochs=num_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成画像と訓練データを可視化する\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 入力の乱数生成\n",
    "batch_size = 8\n",
    "z_dim = 20\n",
    "fixed_z = torch.randn(batch_size, z_dim)\n",
    "fixed_z = fixed_z.view(fixed_z.size(0), fixed_z.size(1), 1, 1)\n",
    "\n",
    "# 画像生成\n",
    "G.eval()\n",
    "fake_images = G(fixed_z.to(device))\n",
    "\n",
    "# 訓練データ\n",
    "batch_iterator = iter(train_dataloader)\n",
    "images = next(batch_iterator)\n",
    "\n",
    "# 出力\n",
    "fig = plt.figure(figsize=(15, 6))\n",
    "for i in range(0,5):\n",
    "    # 上段に訓練データ\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(images[i][0].cpu().detach().numpy(), 'gray')\n",
    "    \n",
    "    # 下段に生成データ\n",
    "    plt.subplot(2, 5, i+6)\n",
    "    plt.imshow(fake_images[i][0].cpu().detach().numpy(), 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attention mapの表示\n",
    "fig = plt.figure(figsize=(15, 6))\n",
    "\n",
    "for i in range(0,5):\n",
    "    # 上段に生成したデータを\n",
    "    plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(fake_images[i][0].cpu().detach().numpy(), 'gray')\n",
    "    \n",
    "    # 下段にattention map１の画像中央のピクセルのデータを\n",
    "    plt.subplot(2, 5, i+6)\n",
    "    am = am[i].view(16,16,16)\n",
    "    am = am[7][7]  # 中央に着目\n",
    "    plt.imshow(am.cpu().detach().numpy(), 'Reds')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
