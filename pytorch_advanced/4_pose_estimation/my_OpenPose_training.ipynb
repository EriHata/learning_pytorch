{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習と検証の実施\n",
    "- 本ファイルでは、OpenPoseの学習と検証の実施を行います。AWSのGPUマシンで計算します。\n",
    "- p2.xlargeで45分ほどかかります。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# パッケージのimport\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.dataloader import make_datapath_list, DataTransform, COCOkeypointsDataset\n",
    "\n",
    "# MS COCO のファイルパスリスト作成\n",
    "train_img_list, train_mask_list, val_img_list, val_mask_list, train_meta_list, val_meta_list = make_datapath_list(rootpath='./data/')\n",
    "# maskは、人なのにアノテーションデータがない部分をmaskしてある\n",
    "\n",
    "# Dataset作成\n",
    "# 本来のtrainデータは\n",
    "train_dataset = COCOkeypointsDataset(val_img_list, val_mask_list, val_meta_list, phase='train', transform=DataTransform())\n",
    "\n",
    "# DataLoader作成\n",
    "batch_size = 32\n",
    "train_dataloader = data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# 辞書型変数にまとめる\n",
    "dataloaders_dict = {'train': train_dataloader, 'val': None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.openpose_net import OpenPoseNet\n",
    "net = OpenPoseNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 損失関数の定義\n",
    "OpenPoseの損失関数はheatmapsとPAFｓ，　それぞれについて正解アノテーションデータとの回帰の誤差<br>\n",
    "平均二乗誤差mseを使い、各stageのheatmapsとPAFｓの全ての誤差を足し合わせる<br>\n",
    "人物が写っているが姿勢のアノテーションデータがない部分の損失は計算しない（maskされている部分)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OpenPoseLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    OpenPoseの損失関数のクラス\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(OpenPoseLoss, self).__init__()\n",
    "        \n",
    "    def forward(self, saved_for_loss, heatmap_target, heat_mask, paf_target, paf_mask):\n",
    "        \"\"\"\n",
    "        損失関数の計算\n",
    "        \n",
    "        Parameters\n",
    "        ----------------\n",
    "        saved_for_loss : OpenPoseNetの出力\n",
    "        \n",
    "        heatmap_target : [num_batch, 19, 46, 46]\n",
    "            正解のアノテーション情報\n",
    "        \n",
    "        heatmap_mask : [num_batch, 19, 46, 46]\n",
    "            heatmap画像のマスク\n",
    "        \n",
    "        paf_target : [num_batch, 38, 46, 46]\n",
    "            正解のPAFのアノテーション情報\n",
    "        \n",
    "        paf_mask : [num_batch, 38, 46, 46]\n",
    "            paf画像のマスク\n",
    "        \n",
    "        Returns\n",
    "        ----------------\n",
    "        loss : テンソル\n",
    "            損失の値\n",
    "            \n",
    "        \"\"\"\n",
    "        \n",
    "        total_loss = 0\n",
    "        \n",
    "        # ステージごとにlossを計算して加算する\n",
    "        for j in range(6):\n",
    "            # PAFsとheatmapにおいてマスクされている部分は無視させる\n",
    "            # PAFs\n",
    "            pred1 = saved_for_loss[j*2] * paf_mask\n",
    "            gt1 = paf_target.float() * paf_mask\n",
    "            \n",
    "            # heatmap\n",
    "            pred2 = saved_for_loss[j*2 + 1] * heat_mask\n",
    "            gt2 = heatmap_target.float() * heat_mask\n",
    "            \n",
    "            total_loss += F.mse_loss(pred1, gt1, reduction='mean') + \\\n",
    "                F.mse_loss(pred2, gt2, reduction='mean')\n",
    "            \n",
    "        return total_loss\n",
    "\n",
    "# 損失関数のインスタンス生成\n",
    "criterion = OpenPoseLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習の実施\n",
    "コード書き終わったらgithubにpushしてawsで学習を実行する\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(net.parameters(), lr=1e-2, momentum=0.9, weight_decay=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習させる関数\n",
    "\n",
    "def train_model(net, dataloaders_dict, criterion, optimizer, num_epochs):\n",
    "    # GPUが使えるか確認\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    print('使用デバイス：　', device)\n",
    "    \n",
    "    # ネットワークをGPUへ\n",
    "    net.to(device)\n",
    "    \n",
    "    # ネットワークがある程度固定であれば高速化させる\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "    # 画像の枚数\n",
    "    num_train_imgs = len(dataloaders_dict['train'].dataset)\n",
    "    batch_size = dataloaders_dict['train'].batch_size\n",
    "    \n",
    "    # イテレーションカウンタをセット\n",
    "    iteration = 1\n",
    "    \n",
    "    # epochのループ\n",
    "    for epoch in range(num_epochs):\n",
    "        # 開始時刻を保存\n",
    "        t_epoch_start = time.time()\n",
    "        t_iter_start = time.time()\n",
    "        epoch_train_loss = 0.0\n",
    "        epoch_val_loss = 0.0\n",
    "        \n",
    "        print('-------------------')\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        print('-------------------')\n",
    "        \n",
    "        # epoch毎にtrainとval\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                net.train()\n",
    "                optimizer.zero_grad()\n",
    "                print(' (train) ')\n",
    "            # 検証は今回はスキップ\n",
    "            else:\n",
    "                continue\n",
    "            \n",
    "            # dataloaderからminibatchずつ取り出すループ\n",
    "            for imgs, heatmap_target, heat_mask, paf_target, paf_mask in dataloaders_dict[phase]:\n",
    "                # minibatchのサイズが1だとバッチノーマライゼーションでエラーになるので避ける\n",
    "                if imgs.size()[0] == 1:\n",
    "                    continue\n",
    "                \n",
    "                # GPUが使えるならGPUにデータを送る\n",
    "                imgs = imgs.to(device)\n",
    "                heatmap_target = heatmap_target.to(device)\n",
    "                heat_mask = heat_mask.to(device)\n",
    "                paf_target = paf_target.to(device)\n",
    "                paf_mask = paf_mask.to(device)\n",
    "                \n",
    "                # optim初期化\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # 順伝播計算\n",
    "                with torch.set_grad_enabled(phase=='train'):\n",
    "                    # (out6_1, out6_2)は使わないので_で代替\n",
    "                    _, saved_for_loss = net(imgs)\n",
    "                    \n",
    "                    # 毎度代入するからlossの初期化はいらないのか？\n",
    "                    loss = criterion(saved_for_loss, heatmap_target, heat_mask, paf_target, paf_mask)\n",
    "                    \n",
    "                    # 訓練時はbackpropagation\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        \n",
    "                        if (iteration % 10 == 0):\n",
    "                            # 10iterにつき1回lossを表示\n",
    "                            t_iter_finish = time.time()\n",
    "                            duration = t_iter_finish - t_iter_start\n",
    "                            print('イテレーション {} || Loss: {:.4f} || 10iter: {:.4f} sec'.format(iteration, loss.item()/batch_size, duration))\n",
    "                            t_iter_start = time.time()\n",
    "                        epoch_train_loss += loss.item()\n",
    "                        iteration += 1\n",
    "                    # 検証時は今回はなし\n",
    "                    \n",
    "            # epochのpahseごとのlossの計\n",
    "        t_epoch_finish = time.time()\n",
    "        print('------------')\n",
    "        print('epoch {} || Epoch_Train_Loss:{:.4f} || Epoch_Val_Loss: {:.4f}'.format(epoch+1, epoch_train_loss/num_train_imgs, 0))\n",
    "        print('timer : {:.4f} sec'.format(t_epoch_finish - t_epoch_start))\n",
    "        t_epoch_start = time.time()\n",
    "        \n",
    "    # 最後にネットワークを保存する\n",
    "    torch.save(net.state_dict(), 'weights/openpose_net_'+str(epoch+1)+'.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用デバイス：　 cuda:0\n",
      "-------------------\n",
      "Epoch 1/2\n",
      "-------------------\n",
      " (train) \n",
      "イテレーション 10 || Loss: 0.0018 || 10iter: 89.9444 sec\n",
      "イテレーション 20 || Loss: 0.0016 || 10iter: 95.5492 sec\n",
      "イテレーション 30 || Loss: 0.0016 || 10iter: 92.5720 sec\n",
      "イテレーション 40 || Loss: 0.0015 || 10iter: 90.6413 sec\n",
      "イテレーション 50 || Loss: 0.0016 || 10iter: 90.7619 sec\n",
      "イテレーション 60 || Loss: 0.0016 || 10iter: 93.1956 sec\n",
      "イテレーション 70 || Loss: 0.0013 || 10iter: 91.7621 sec\n",
      "イテレーション 80 || Loss: 0.0013 || 10iter: 92.2868 sec\n",
      "イテレーション 90 || Loss: 0.0016 || 10iter: 90.4380 sec\n",
      "イテレーション 100 || Loss: 0.0016 || 10iter: 91.8847 sec\n",
      "イテレーション 110 || Loss: 0.0012 || 10iter: 93.1834 sec\n",
      "イテレーション 120 || Loss: 0.0017 || 10iter: 90.7749 sec\n",
      "イテレーション 130 || Loss: 0.0015 || 10iter: 89.3018 sec\n",
      "イテレーション 140 || Loss: 0.0014 || 10iter: 90.6615 sec\n",
      "イテレーション 150 || Loss: 0.0013 || 10iter: 91.0294 sec\n",
      "------------\n",
      "epoch 1 || Epoch_Train_Loss:0.0016 || Epoch_Val_Loss: 0.0000\n",
      "timer : 1447.6414 sec\n",
      "-------------------\n",
      "Epoch 2/2\n",
      "-------------------\n",
      " (train) \n",
      "イテレーション 160 || Loss: 0.0014 || 10iter: 62.7744 sec\n",
      "イテレーション 170 || Loss: 0.0014 || 10iter: 93.5940 sec\n",
      "イテレーション 180 || Loss: 0.0015 || 10iter: 92.5313 sec\n",
      "イテレーション 190 || Loss: 0.0015 || 10iter: 89.9875 sec\n",
      "イテレーション 200 || Loss: 0.0015 || 10iter: 92.6157 sec\n",
      "イテレーション 210 || Loss: 0.0015 || 10iter: 90.3879 sec\n",
      "イテレーション 220 || Loss: 0.0012 || 10iter: 93.9854 sec\n",
      "イテレーション 230 || Loss: 0.0016 || 10iter: 91.5219 sec\n",
      "イテレーション 240 || Loss: 0.0015 || 10iter: 91.4152 sec\n",
      "イテレーション 250 || Loss: 0.0014 || 10iter: 93.1476 sec\n",
      "イテレーション 260 || Loss: 0.0016 || 10iter: 90.8253 sec\n",
      "イテレーション 270 || Loss: 0.0015 || 10iter: 92.5156 sec\n",
      "イテレーション 280 || Loss: 0.0012 || 10iter: 90.5249 sec\n",
      "イテレーション 290 || Loss: 0.0017 || 10iter: 91.3180 sec\n",
      "イテレーション 300 || Loss: 0.0015 || 10iter: 90.8108 sec\n",
      "------------\n",
      "epoch 2 || Epoch_Train_Loss:0.0014 || Epoch_Val_Loss: 0.0000\n",
      "timer : 1442.5143 sec\n"
     ]
    }
   ],
   "source": [
    "# 学習を実行\n",
    "num_epochs = 2\n",
    "train_model(net, dataloaders_dict, criterion, optimizer, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lossが最初からある程度小さいのはいいのか？学習全体を通してあまりlossが減っていない...\n",
    "# お手本だとイテレーション 10 || Loss: 0.0094 ||から始まっていた"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
