{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習と検証の実施\n",
    "- 本ファイルでは、OpenPoseの学習と検証の実施を行います。AWSのGPUマシンで計算します。\n",
    "- p2.xlargeで45分ほどかかります。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eri/opt/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# パッケージのimport\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils.dataloader import make_datapath_list, DataTransform, COCOkeypointsDataset\n",
    "\n",
    "# MS COCO のファイルパスリスト作成\n",
    "train_img_list, train_mask_list, val_img_list, val_mask_list, train_meta_list, val_meta_list = make_datapath_list(rootpath='./data/')\n",
    "# maskは、人なのにアノテーションデータがない部分をmaskしてある\n",
    "\n",
    "# Dataset作成\n",
    "# 本来のtrainデータは\n",
    "train_dataset = COCOkeypointsDataset(val_img_list, val_mask_list, val_meta_list, phase='train', transform=DataTransform())\n",
    "\n",
    "# DataLoader作成\n",
    "batch_size = 32\n",
    "train_dataloader = data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# 辞書型変数にまとめる\n",
    "dataloaders_dict = {'train': train_dataloader, 'val': None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.openpose_net import OpenPoseNet\n",
    "net = OpenPoseNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 損失関数の定義\n",
    "OpenPoseの損失関数はheatmapsとPAFｓ，　それぞれについて正解アノテーションデータとの回帰の誤差<br>\n",
    "平均二乗誤差mseを使い、各stageのheatmapsとPAFｓの全ての誤差を足し合わせる<br>\n",
    "人物が写っているが姿勢のアノテーションデータがない部分の損失は計算しない（maskされている部分)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OpenPoseLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    OpenPoseの損失関数のクラス\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(OpenPoseLoss, self).__init__()\n",
    "        \n",
    "    def forward(self, saved_for_loss, heatmap_target, heat_mask, paf_target, paf_mask):\n",
    "        \"\"\"\n",
    "        損失関数の計算\n",
    "        \n",
    "        Parameters\n",
    "        ----------------\n",
    "        saved_for_loss : OpenPoseNetの出力\n",
    "        \n",
    "        heatmap_target : [num_batch, 19, 46, 46]\n",
    "            正解のアノテーション情報\n",
    "        \n",
    "        heatmap_mask : [num_batch, 19, 46, 46]\n",
    "            heatmap画像のマスク\n",
    "        \n",
    "        paf_target : [num_batch, 38, 46, 46]\n",
    "            正解のPAFのアノテーション情報\n",
    "        \n",
    "        paf_mask : [num_batch, 38, 46, 46]\n",
    "            paf画像のマスク\n",
    "        \n",
    "        Returns\n",
    "        ----------------\n",
    "        loss : テンソル\n",
    "            損失の値\n",
    "            \n",
    "        \"\"\"\n",
    "        \n",
    "        total_loss = 0\n",
    "        \n",
    "        # ステージごとにlossを計算して加算する\n",
    "        for j in range(6):\n",
    "            # PAFsとheatmapにおいてマスクされている部分は無視させる\n",
    "            # PAFs\n",
    "            pred1 = saved_for_loss[j*2] * paf_mask\n",
    "            gt1 = paf_target.float() * paf_mask\n",
    "            \n",
    "            # heatmap\n",
    "            pred2 = saved_for_loss[j*2 + 1] * heat_mask\n",
    "            gt2 = heatmap_target.float() * heat_mask\n",
    "            \n",
    "            total_loss += F.mse_loss(pred1, gt1, reduction='mean') + \\\n",
    "                F.mse_loss(pred2, gt2, reduction='mean')\n",
    "            \n",
    "        return total_loss\n",
    "\n",
    "# 損失関数のインスタンス生成\n",
    "criterion = OpenPoseLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習の実施\n",
    "コード書き終わったらgithubにpushしてawsで学習を実行する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(net.parameters(), lr=1e-2, momentum=0.9, weight_decay=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習させる関数\n",
    "\n",
    "def train_model(net, dataloaders_dict, criterion, optimizer, num_epochs):\n",
    "    # GPUが使えるか確認\n",
    "    device = torch.device('cuda:0' if torch.cuda.available() else 'cpu')\n",
    "    print('使用デバイス：　', device)\n",
    "    \n",
    "    # ネットワークをGPUへ\n",
    "    net.to(device)\n",
    "    \n",
    "    # ネットワークがある程度固定であれば高速化させる\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    \n",
    "    # 画像の枚数\n",
    "    num_train_imgs = len(dataloaders_dict['train'].dataset)\n",
    "    batch_size = dataloaders_dict['train'].batch_size\n",
    "    \n",
    "    # イテレーションカウンタをセット\n",
    "    iteration = 1\n",
    "    \n",
    "    # epochのループ\n",
    "    for epoch in range(num_epochs):\n",
    "        # 開始時刻を保存\n",
    "        t_epoch_start = time.time()\n",
    "        t_iter_start = time.time()\n",
    "        epoch_train_loss = 0.0\n",
    "        epoch_val_loss = 0.0\n",
    "        \n",
    "        print('-------------------')\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        print('-------------------')\n",
    "        \n",
    "        # epoch毎にtrainとval\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                net.train()\n",
    "                optimizer.zero_grad()\n",
    "                print(' (train) ')\n",
    "            # 検証は今回はスキップ\n",
    "            else:\n",
    "                continue\n",
    "            \n",
    "            # dataloaderからminibatchずつ取り出すループ\n",
    "            for imgs, heatmap_target, heat_mask, paf_target, paf_mask in dataloaders_dict['phase']:\n",
    "                # minibatchのサイズが1だとバッチノーマライゼーションでエラーになるので避ける\n",
    "                if imgs.size()[0] == 1:\n",
    "                    continue\n",
    "                \n",
    "                # GPUが使えるならGPUにデータを送る\n",
    "                imgs = imgs.to(device)\n",
    "                heatmap_target = heatmap_target.to(device)\n",
    "                heat_mask = heat_mask.to(device)\n",
    "                paf_target = paf_target.to(device)\n",
    "                paf_mask = paf_mask.to(device)\n",
    "                \n",
    "                # optim初期化\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                # 順伝播計算\n",
    "                with torch.set_grad_enabled(phase=='train'):\n",
    "                    # (out6_1, out6_2)は使わないので_で代替\n",
    "                    _, saved_for_loss = net(imgs)\n",
    "                    \n",
    "                    # 毎度代入するからlossの初期化はいらないのか？\n",
    "                    loss = criterion(saved_for_loss, heatmap_target, heat_mask, paf_target, paf_mask)\n",
    "                    \n",
    "                    # 訓練時はbackpropagation\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        \n",
    "                        if (iteration % 10 == 0):\n",
    "                            # 10iterにつき1回lossを表示\n",
    "                            t_iter_finish = time.time()\n",
    "                            duration = t_iter_finish - t_iter_start\n",
    "                            print('イテレーション {} || Loss: {:.4f} || 10iter: {:.4f} sec'.format(iteration, loss.item()/batch_size, duration))\n",
    "                            t_iter_start = time.time()\n",
    "                            epoch_train_loss += loss.item()\n",
    "                            iteration += 1\n",
    "                    # 検証時は今回はなし\n",
    "                    \n",
    "            # epochのpahseごとのlossの計算\n",
    "            t_epoch_finish = time.time()\n",
    "            print('------------')\n",
    "            print('epoch {} || Epoch_Train_Loss:{:.4f} || Epoch_Val_Loss: {:.4f}'.format(epoch+1, epoch_train_loss/num_train_imgs, 0))\n",
    "            print('timer : {:.4f} sec'.format(t_epoch_finish - t_epoch_start))\n",
    "            t_epoch_start = time.time()\n",
    "        \n",
    "        # 最後にネットワークを保存する\n",
    "        torch.save(net.state_dict(), 'weights/openpose_net_'+str(epoch+1)+'.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習を実行\n",
    "num_epochs = 2\n",
    "train_model(net, dataloaders_dict, criterion, optimizer, num_epochs=num_epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
